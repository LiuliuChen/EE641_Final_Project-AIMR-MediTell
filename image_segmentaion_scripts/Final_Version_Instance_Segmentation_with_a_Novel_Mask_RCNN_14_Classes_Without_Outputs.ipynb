{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Start"
      ],
      "metadata": {
        "id": "dnxgvSsrpZkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import shutil\n",
        "import time\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageDraw\n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
      ],
      "metadata": {
        "id": "B-WuCsLoquBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab Import"
      ],
      "metadata": {
        "id": "hNaykqxXnDIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# > Mounted at /content/drive\n",
        "\n",
        "!unzip /content/drive/MyDrive/ee641/Project_Datasets/ChestXDet_Dataset.zip"
      ],
      "metadata": {
        "id": "EGRn_QqE0u4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "f_train = open('/content/ChestX_Det_train.json')\n",
        "f_test = open('/content/ChestX_Det_test.json')\n",
        "train_data_anns = json.load(f_train)\n",
        "test_data_anns = json.load(f_test)"
      ],
      "metadata": {
        "id": "0a5pgwkp2c9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_anns[5].keys())\n",
        "print(train_data_anns[5]['file_name'])\n",
        "print(train_data_anns[5]['syms'])\n",
        "print(train_data_anns[5]['boxes'])\n",
        "print(train_data_anns[5]['polygons'])\n",
        "print('***')\n",
        "print((train_data_anns[5]['boxes'])[0])\n",
        "print((train_data_anns[5]['polygons'])[0])"
      ],
      "metadata": {
        "id": "okjwdF9f2yrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_syms = []\n",
        "for i in train_data_anns:\n",
        "  temp = i['syms']\n",
        "  for j in temp:\n",
        "    if((j in list_of_syms) == False):\n",
        "      list_of_syms.append(j)\n",
        "print(list_of_syms)\n",
        "print(len(list_of_syms))\n",
        "\n",
        "temp_dict = {}\n",
        "counter = 1\n",
        "for i in list_of_syms:\n",
        "  if((i in temp_dict) == False):\n",
        "    temp_dict[i] = counter\n",
        "    counter += 1\n",
        "print(temp_dict)\n",
        "mapping_labels = temp_dict"
      ],
      "metadata": {
        "id": "e_hQyn7VaavP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class NoneTransform(object):\n",
        "#     ''' Does nothing to the image. To be used instead of None '''\n",
        "    \n",
        "#     def __call__(self, image):       \n",
        "#         return image\n",
        "\n",
        "# temp_transform = transforms.Compose([\n",
        "#             transforms.ToTensor(),            \n",
        "#             transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform()            \n",
        "#             ]) "
      ],
      "metadata": {
        "id": "e1Vyy7VATwj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_matrix = np.zeros((224,224,3))\n",
        "for i in range(len(train_data_anns)):\n",
        "  img_name = (train_data_anns[i])['file_name']\n",
        "  path = '/content/ChestXDet_Dataset/train/' + img_name\n",
        "  temp_img = Image.open(path)\n",
        "  temp_img = temp_img.convert('RGB')\n",
        "  temp_img = temp_img.resize((224, 224))\n",
        "  temp_img_tensor = temp_transform(temp_img)\n",
        "  temp_img_tensor = temp_img_tensor.permute(1, 2, 0)\n",
        "  temp_img_numpy = temp_img_tensor.numpy()\n",
        "  sum_matrix = sum_matrix + temp_img_numpy\n",
        "\n",
        "sum_matrix_1d = sum_matrix[:,:,0]\n",
        "sum_matrix_1d_avg = sum_matrix_1d / len(train_data_anns)\n",
        "mean_chest = np.mean(sum_matrix_1d_avg, axis = None)\n",
        "std_chest = np.std(sum_matrix_1d_avg, axis = None)\n",
        "print(\"Mean of the Gray Scale Training Chest Images of Pixels = \", mean_chest)\n",
        "print(\"Std of the Gray Scale Training Chest Images of Pixels = \", std_chest)"
      ],
      "metadata": {
        "id": "Amvv16xOF3AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_filled_masks_on_image(image_np, polygons):\n",
        "\n",
        "    image = Image.fromarray(image_np)\n",
        "    img_with_masks = image.copy()\n",
        "    mask_color = (0, 255, 0, 128)  \n",
        "    mask_layer = Image.new('RGBA', img_with_masks.size, (0, 0, 0, 0))\n",
        "    draw_ctx = ImageDraw.Draw(mask_layer)\n",
        "    \n",
        "    for polygon in polygons:\n",
        "        draw_ctx.polygon(polygon, fill=mask_color)\n",
        "    img_with_masks.paste(mask_layer, mask=mask_layer.split()[3], box=(0, 0))\n",
        "    img_with_masks_np = np.array(img_with_masks)\n",
        "\n",
        "    return img_with_masks_np\n"
      ],
      "metadata": {
        "id": "unQqOPnrYKze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_img = Image.open('/content/ChestXDet_Dataset/train/36204.png')\n",
        "temp_img = temp_img.resize((224, 224))\n",
        "temp_img = temp_img.convert('RGB')\n",
        "masks = train_data_anns[4]['polygons']\n",
        "print(masks)\n",
        "\n",
        "#masks_tuple = [[tuple(coords) for coords in polygon] for polygon in masks]\n",
        "rescaled_list = [\n",
        "    [\n",
        "        (coord[0] * 224 / 1024, coord[1] * 224 / 1024)\n",
        "        for coord in polygon\n",
        "    ]\n",
        "    for polygon in masks\n",
        "]\n",
        "print(rescaled_list)\n",
        "\n",
        "temp_img = np.array(temp_img)\n",
        "print(temp_img.shape)\n",
        "\n",
        "image_with_actual_masks = plot_filled_masks_on_image(temp_img, rescaled_list)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(image_with_actual_masks)\n",
        "plt.show()\n",
        "\n",
        "print(train_data_anns[4])\n"
      ],
      "metadata": {
        "id": "4wUpoHV-XuOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset Class"
      ],
      "metadata": {
        "id": "4MIfTKBeGiS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from PIL import Image, ImageDraw\n",
        "from PIL import ImagePath "
      ],
      "metadata": {
        "id": "cXgrLne-F2fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def angle(point, centroid):\n",
        "    dx, dy = point[0] - centroid[0], point[1] - centroid[1]\n",
        "    return math.atan2(dy, dx)"
      ],
      "metadata": {
        "id": "4QDIslK3-Jn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_syms = []\n",
        "for i in train_data_anns:\n",
        "  temp = i['syms']\n",
        "  for j in temp:\n",
        "    if((j in list_of_syms) == False):\n",
        "      list_of_syms.append(j)\n",
        "print(list_of_syms)\n",
        "print(len(list_of_syms))\n",
        "\n",
        "temp_dict = {}\n",
        "counter = 1\n",
        "for i in list_of_syms:\n",
        "  if((i in temp_dict) == False):\n",
        "    temp_dict[i] = counter\n",
        "    counter += 1\n",
        "print(temp_dict)\n",
        "mapping_labels = temp_dict\n",
        "map_labels = mapping_labels"
      ],
      "metadata": {
        "id": "IzQyoMJhcAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChestXDet_Dataset(Dataset):\n",
        "  def __init__(self, images_root_dir, anns_dir, transform=None, cuda = True, mapping_labels = None):\n",
        "    self.images_root_dir = images_root_dir\n",
        "    self.anns_dir = anns_dir\n",
        "    self.transform = transform\n",
        "    self.image_names = os.listdir(images_root_dir)\n",
        "    anns_json = open(anns_dir)\n",
        "    self.img_anns = json.load(anns_json)\n",
        "    list_of_annotated_image_filenames = []\n",
        "\n",
        "    self.mapping_labels = mapping_labels\n",
        "\n",
        "    for i in range(len(self.image_names)):\n",
        "      temp_image_filename = self.image_names[i]\n",
        "      temp_image_directory = self.images_root_dir + '/' + temp_image_filename\n",
        "      temp_annotation_index =  [i for i,_ in enumerate(self.img_anns) if _['file_name'] == temp_image_filename][0]\n",
        "      temp_annotations = self.img_anns[temp_annotation_index]\n",
        "      if(len(temp_annotations['boxes']) > 0):\n",
        "        list_of_annotated_image_filenames.append(temp_image_filename)\n",
        "    \n",
        "    self.annotated_image_names = list_of_annotated_image_filenames\n",
        "\n",
        "    self.img_h = 224\n",
        "    self.img_w = 224\n",
        "    #self.org_image_width = 1024\n",
        "    #self.org_image_height = 1024\n",
        "    self.cuda = cuda\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotated_image_names)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image_filename = self.annotated_image_names[idx]\n",
        "    annotation_index =  [i for i,_ in enumerate(self.img_anns) if _['file_name'] == image_filename][0]\n",
        "    image_directory = self.images_root_dir + '/' + image_filename\n",
        "\n",
        "    image = Image.open(image_directory)\n",
        "    org_image_width = (image.size)[0]\n",
        "    org_image_height = (image.size)[1]\n",
        "\n",
        "    #print(org_image_width)\n",
        "    #print(org_image_height)\n",
        "\n",
        "    annotations = self.img_anns[annotation_index]\n",
        "\n",
        "    list_of_bounding_box_coordinates = []\n",
        "    list_of_masks = []\n",
        "    list_of_polys = []\n",
        "    labels = []\n",
        "\n",
        "    temp_polygons = annotations['polygons']\n",
        "    temp_boxes = annotations['boxes']\n",
        "    temp_labels = annotations['syms']\n",
        "\n",
        "    for i in range(len(temp_boxes)):\n",
        "      x1_converted = ((temp_boxes[i])[0]) * (self.img_w / org_image_width)\n",
        "      y1_converted = ((temp_boxes[i])[1]) * (self.img_h / org_image_height)\n",
        "      x2_converted = ((temp_boxes[i])[2]) * (self.img_w / org_image_width)\n",
        "      y2_converted = ((temp_boxes[i])[3]) * (self.img_h / org_image_height)\n",
        "      #temp_bbox_coors = np.array([x1_converted, y1_converted, x2_converted, y2_converted], dtype = np.float32)\n",
        "      temp_bbox_coors = [x1_converted, y1_converted, x2_converted, y2_converted]\n",
        "      #torch_temp_bbox_coors = torch.FloatTensor(torch.from_numpy(temp_bbox_coors))\n",
        "      list_of_bounding_box_coordinates.append(temp_bbox_coors)\n",
        "      labels.append(self.mapping_labels[temp_labels[i]])\n",
        "\n",
        "      poly_i = temp_polygons[i]\n",
        "      #rescaled_list = [(coord[0] * self.img_w / org_image_width, coord[1] * self.img_h / org_image_height) for coord in poly_i]\n",
        "      temp_flat_list_polygons = list(itertools.chain(*poly_i))\n",
        "      rescaled_flattened_polygons = []\n",
        "      for k in range(int(len(temp_flat_list_polygons) / 2)):\n",
        "        rescaled_x_coor = temp_flat_list_polygons[2*k] * (self.img_w / org_image_width)\n",
        "        rescaled_y_coor = temp_flat_list_polygons[2*k+1] * (self.img_h / org_image_height)\n",
        "        rescaled_flattened_polygons.append(rescaled_x_coor)\n",
        "        rescaled_flattened_polygons.append(rescaled_y_coor)\n",
        "      temp_mask_image = Image.new('L', (self.img_w, self.img_h), 0)\n",
        "      poly_rescaled_tuples = [(x, y) for x, y in zip(rescaled_flattened_polygons[::2], rescaled_flattened_polygons[1::2])]\n",
        "      #ImageDraw.Draw(temp_mask_image).polygon(rescaled_list, outline=1, fill=1)\n",
        "      ImageDraw.Draw(temp_mask_image).polygon(poly_rescaled_tuples, outline=1, fill=1)\n",
        "\n",
        "      temp_mask = list(np.array(temp_mask_image, dtype = np.uint8))\n",
        "      #torch_mask = torch.from_numpy(temp_mask)\n",
        "      #list_of_masks.append(torch_mask)\n",
        "      list_of_masks.append(temp_mask)\n",
        "      #list_of_polys.append(rescaled_list)\n",
        "      list_of_polys.append(poly_rescaled_tuples)\n",
        "\n",
        "      \n",
        "    # if(image.mode != 'RGB'):\n",
        "    #   image = image.convert('RGB')\n",
        "    \n",
        "    image = image.resize((self.img_h, self.img_w))\n",
        "\n",
        "    if(self.transform != None):\n",
        "      image = self.transform(image)\n",
        "\n",
        "    #print(image.shape)\n",
        "\n",
        "    #image = image.permute(2, 0, 1)\n",
        "\n",
        "\n",
        "    torch_labels = torch.LongTensor(labels)\n",
        "    torch_list_of_bounding_box_coordinates = torch.FloatTensor(list_of_bounding_box_coordinates)\n",
        "    torch_list_of_masks = torch.ByteTensor(list_of_masks)\n",
        "    #torch_list_of_polys = torch.FloatTensor(list_of_polys)\n",
        "\n",
        "    target_dict = {}\n",
        "\n",
        "    target_dict['boxes'] = torch_list_of_bounding_box_coordinates\n",
        "    target_dict['labels'] = torch_labels\n",
        "    target_dict['masks'] = torch_list_of_masks\n",
        "    target_dict['polys'] = list_of_polys\n",
        "\n",
        "    target = target_dict\n",
        "\n",
        "    return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    targets = []\n",
        "    #val_bbox_coordinates = []\n",
        "    #plain_images = []\n",
        "    #image_heights = []\n",
        "    #image_widths = []\n",
        "    for item in batch:\n",
        "        images.append(item[0])\n",
        "        targets.append(item[1])\n",
        "    images = torch.stack(images, 0)\n",
        "    #if(mode == 'train'):\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "4pOo8YeKw5GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "c0q_slmAW4WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Factory"
      ],
      "metadata": {
        "id": "GnWf0Z9HYdb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_V2_Weights\n",
        "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
        "    #model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "rLc9Rm2wGZPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "sbpJsUcuZYoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "root_directory_train = '/content/ChestXDet_Dataset/train'\n",
        "root_directory_val = '/content/ChestXDet_Dataset/test'\n",
        "annotation_file_directory_train = '/content/ChestX_Det_train.json'\n",
        "annotation_file_directory_val = '/content/ChestX_Det_test.json'\n",
        "\n",
        "class NoneTransform(object):\n",
        "  def __call__(self, image):\n",
        "    return image\n",
        "\n",
        "class GrayscaleToRGB:\n",
        "  def __call__(self, image):\n",
        "    if image.mode != 'RGB':\n",
        "      return image.convert('RGB')\n",
        "    return image\n",
        "\n",
        "mean_chest = 0.5240804197105211\n",
        "std_chest = 0.17148634738092733\n",
        "\n",
        "my_transform_with_Normalization = transforms.Compose([\n",
        "    GrayscaleToRGB(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    #transforms.Normalize([mean_chest, mean_chest, mean_chest], [std_chest, std_chest, std_chest])\n",
        "])\n",
        "\n",
        "\n",
        "#Mean of the Gray Scale Training Chest Images of Pixels =  0.5240804197105211\n",
        "#Std of the Gray Scale Training Chest Images of Pixels =  0.17148634738092733\n",
        "\n",
        "\n",
        "\n",
        "# my_transform_Specialized = transforms.Compose([\n",
        "#             transforms.ToTensor(),            \n",
        "#             transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform(),\n",
        "#             transforms.Normalize([mean_chest, mean_chest, mean_chest], [std_chest, std_chest, std_chest])                \n",
        "#             ]) \n",
        "\n",
        "# my_transform_ImageNet = transforms.Compose([\n",
        "#             transforms.ToTensor(),            \n",
        "#             transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform(),\n",
        "#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                \n",
        "#             ]) \n",
        "\n",
        "train_dataset = ChestXDet_Dataset(root_directory_train, annotation_file_directory_train, transform=my_transform_with_Normalization, cuda=True, mapping_labels = map_labels)\n",
        "val_dataset = ChestXDet_Dataset(root_directory_val, annotation_file_directory_val, transform=my_transform_with_Normalization, cuda=True, mapping_labels = map_labels)"
      ],
      "metadata": {
        "id": "c_IKPsfCXSPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, shuffle = True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, shuffle = False, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "VNztPcOmccyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Curves Plotting"
      ],
      "metadata": {
        "id": "iKyoxxjMV6-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N63qZW_FyY-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotter(losses_classifier, losses_box_reg, losses_objectness, losses_rpn_box_reg, losses_mask):\n",
        "  \n",
        "  x_axis = np.arange(1,len(losses_classifier)+1,1)\n",
        "  y_axis_1 = losses_classifier\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1,'blue', linewidth=1.5, label = 'Negative Log-Likelihood Classification Loss')\n",
        "\n",
        "  plt.title('Training Negative Log-Likelihood Classification Loss vs. Epochs')\n",
        "  plt.xticks(np.arange(1,len(losses_classifier)+1,1))\n",
        "  plt.yticks(np.arange(0,max(losses_classifier),0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Negative Log-Likelihood Classification Loss')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  x_axis = np.arange(1,len(losses_box_reg)+1,1)\n",
        "  y_axis_1 = losses_box_reg\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1,'red', linewidth=1.5, label = 'Regression Loss for predicted Bounding Box Coordinates')\n",
        "\n",
        "  plt.title('Regression Loss for predicted Bounding Box Coordinates vs. Epochs')\n",
        "  plt.xticks(np.arange(1,len(losses_box_reg)+1,1))\n",
        "  plt.yticks(np.arange(0,max(losses_box_reg),0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Regression Loss for predicted Bounding Box Coordinates')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  x_axis = np.arange(1,len(losses_objectness)+1,1)\n",
        "  y_axis_1 = losses_objectness\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1,'green', linewidth=1.5, label = 'Binary Cross-Entropy Loss for RPN Objectness')\n",
        "\n",
        "  plt.title('Binary Cross-Entropy Loss for RPN Objectness vs. Epochs')\n",
        "  plt.xticks(np.arange(1,len(losses_objectness)+1,1))\n",
        "  plt.yticks(np.arange(0,max(losses_objectness),0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Binary Cross-Entropy Loss for RPN Objectness')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  x_axis = np.arange(1,len(losses_rpn_box_reg)+1,1)\n",
        "  y_axis_1 = losses_rpn_box_reg\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1,'gray', linewidth=1.5, label = 'Regression Loss for RPN Network Box Coordinates')\n",
        "\n",
        "  plt.title('Regression Loss for RPN Network Box Coordinates vs. Epochs')\n",
        "  plt.xticks(np.arange(1,len(losses_rpn_box_reg)+1,1))\n",
        "  plt.yticks(np.arange(0,max(losses_rpn_box_reg),0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Regression Loss for RPN Network Box Coordinates')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  x_axis = np.arange(1,len(losses_mask)+1,1)\n",
        "  y_axis_1 = losses_mask\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1,'blue', linewidth=1.5, label = 'Mask Loss')\n",
        "\n",
        "  plt.title('Training Mask Loss vs. Epochs')\n",
        "  plt.xticks(np.arange(1,len(losses_mask)+1,1))\n",
        "  plt.yticks(np.arange(0,max(losses_mask),0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Negative Log-Likelihood Classification Loss')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "dLMFBYqVx0XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Metrics Plotting"
      ],
      "metadata": {
        "id": "Rezbsd-SJcCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotter_2(scores_dict):\n",
        "\n",
        "  acc_tr_epochs = scores_dict['acc_tr']\n",
        "  pre_tr_epochs = scores_dict['pre_tr']  \n",
        "  rec_tr_epochs = scores_dict['rec_tr'] \n",
        "  f1_tr_epochs = scores_dict['f1_tr']  \n",
        "  dice_tr_epochs = scores_dict['dice_tr']\n",
        "  iou_tr_epochs = scores_dict['iou_tr'] \n",
        "\n",
        "  acc_val_epochs = scores_dict['acc_val'] \n",
        "  pre_val_epochs = scores_dict['pre_val']\n",
        "  rec_val_epochs = scores_dict['rec_val'] \n",
        "  f1_val_epochs = scores_dict['f1_val'] \n",
        "  dice_val_epochs = scores_dict['dice_val']\n",
        "  iou_val_epochs = scores_dict['iou_val']\n",
        "  \n",
        "  x_axis = np.arange(1,len(acc_tr_epochs)+1,1)\n",
        "\n",
        "  y_axis_1 = acc_tr_epochs\n",
        "  y_axis_2 = acc_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Accuracy')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Accuracy')\n",
        "\n",
        "  plt.title('Training Mask Accuracy vs. Validation Mask Accuracy through Epochs')\n",
        "  plt.xticks(np.arange(1,len(acc_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0, max(acc_tr_epochs + acc_val_epochs) + 0.05, 0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Accuracy')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = pre_tr_epochs\n",
        "  y_axis_2 = pre_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Precision')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Precision')\n",
        "\n",
        "  plt.title('Training Mask Precision vs. Validation Mask Precision through Epochs')\n",
        "  plt.xticks(np.arange(1,len(pre_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0, max(pre_tr_epochs + pre_val_epochs) + 0.05,0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Precision')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = rec_tr_epochs\n",
        "  y_axis_2 = rec_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Recall')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Recall')\n",
        "\n",
        "  plt.title('Training Mask Recall vs. Validation Mask Recall through Epochs')\n",
        "  plt.xticks(np.arange(1,len(rec_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0,max(rec_tr_epochs + rec_val_epochs) + 0.05,0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Recall')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "  y_axis_1 = f1_tr_epochs\n",
        "  y_axis_2 = f1_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask F1-Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask F1-Score')\n",
        "\n",
        "  plt.title('Training Mask F1-Score vs. Validation Mask F1-Score through Epochs')\n",
        "  plt.xticks(np.arange(1,len(f1_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0,max(f1_tr_epochs + f1_val_epochs) + 0.05,0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask F1-Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = dice_tr_epochs\n",
        "  y_axis_2 = dice_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask DICE-Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask DICE-Score')\n",
        "\n",
        "  plt.title('Training Mask DICE-Score vs. Validation Mask DICE-Score through Epochs')\n",
        "  plt.xticks(np.arange(1,len(dice_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0,max(dice_tr_epochs + dice_val_epochs) + 0.05,0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask DICE-Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = iou_tr_epochs\n",
        "  y_axis_2 = iou_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Intersection over Union Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Intersection over Union Score')\n",
        "\n",
        "  plt.title('Training Mask IoU Score vs. Validation Mask IoU Score through Epochs')\n",
        "  plt.xticks(np.arange(1,len(iou_tr_epochs)+1,1))\n",
        "  plt.yticks(np.arange(0,max(iou_tr_epochs + iou_val_epochs) + 0.05,0.01))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Intersection over Union Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "xIc0t1KZXeKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotter_3(scores_dict):\n",
        "\n",
        "  acc_tr_epochs = scores_dict['acc_tr']\n",
        "  pre_tr_epochs = scores_dict['pre_tr']  \n",
        "  rec_tr_epochs = scores_dict['rec_tr'] \n",
        "  f1_tr_epochs = scores_dict['f1_tr']  \n",
        "  dice_tr_epochs = scores_dict['dice_tr']\n",
        "  iou_tr_epochs = scores_dict['iou_tr'] \n",
        "\n",
        "  acc_val_epochs = scores_dict['acc_val'] \n",
        "  pre_val_epochs = scores_dict['pre_val']\n",
        "  rec_val_epochs = scores_dict['rec_val'] \n",
        "  f1_val_epochs = scores_dict['f1_val'] \n",
        "  dice_val_epochs = scores_dict['dice_val']\n",
        "  iou_val_epochs = scores_dict['iou_val']\n",
        "  \n",
        "  x_axis = np.arange(1,2*len(acc_tr_epochs)+1,2)\n",
        "\n",
        "  y_axis_1 = acc_tr_epochs\n",
        "  y_axis_2 = acc_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Accuracy')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Accuracy')\n",
        "\n",
        "  plt.title('Training Mask Accuracy vs. Validation Mask Accuracy through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0, max(acc_tr_epochs + acc_val_epochs) + 0.05, 0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Accuracy')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = pre_tr_epochs\n",
        "  y_axis_2 = pre_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Precision')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Precision')\n",
        "\n",
        "  plt.title('Training Mask Precision vs. Validation Mask Precision through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0, max(pre_tr_epochs + pre_val_epochs) + 0.05,0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Precision')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = rec_tr_epochs\n",
        "  y_axis_2 = rec_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Recall')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Recall')\n",
        "\n",
        "  plt.title('Training Mask Recall vs. Validation Mask Recall through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0,max(rec_tr_epochs + rec_val_epochs) + 0.05,0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Recall')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "  y_axis_1 = f1_tr_epochs\n",
        "  y_axis_2 = f1_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask F1-Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask F1-Score')\n",
        "\n",
        "  plt.title('Training Mask F1-Score vs. Validation Mask F1-Score through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0,max(f1_tr_epochs + f1_val_epochs) + 0.05,0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask F1-Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = dice_tr_epochs\n",
        "  y_axis_2 = dice_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask DICE-Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask DICE-Score')\n",
        "\n",
        "  plt.title('Training Mask DICE-Score vs. Validation Mask DICE-Score through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0,max(dice_tr_epochs + dice_val_epochs) + 0.05,0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask DICE-Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  y_axis_1 = iou_tr_epochs\n",
        "  y_axis_2 = iou_val_epochs\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(25,25))\n",
        "\n",
        "  ax.plot(x_axis, y_axis_1, 'green', linewidth=1.5, label = 'Training Mask Intersection over Union Score')\n",
        "  ax.plot(x_axis, y_axis_2, 'blue', linewidth=1.5, label = 'Validation Mask Intersection over Union Score')\n",
        "\n",
        "  plt.title('Training Mask IoU Score vs. Validation Mask IoU Score through Epochs')\n",
        "  plt.xticks(x_axis)\n",
        "  plt.yticks(np.arange(0,max(iou_tr_epochs + iou_val_epochs) + 0.05,0.02))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mask Intersection over Union Score')\n",
        "  plt.legend(loc = 'upper right')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "FJvs1GdrXZnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize_image(normalized_image, mean, std):\n",
        "    normalized_image = normalized_image.astype(np.float32)\n",
        "    denormalized_image = np.zeros_like(normalized_image)\n",
        "    mean = np.array(mean)\n",
        "    std = np.array(std)\n",
        "\n",
        "    for channel in range(3):\n",
        "        denormalized_image[channel, :, :] = (normalized_image[channel, :, :] * std[channel]) + mean[channel]\n",
        "\n",
        "    denormalized_image = (denormalized_image - denormalized_image.min()) / (denormalized_image.max() - denormalized_image.min()) * 255\n",
        "    denormalized_image = denormalized_image.astype(np.uint8)\n",
        "    denormalized_image = np.transpose(denormalized_image, (1, 2, 0))\n",
        "\n",
        "    return denormalized_image"
      ],
      "metadata": {
        "id": "VtPlWHImmWb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_chest = 0.5240804197105211\n",
        "std_chest = 0.17148634738092733"
      ],
      "metadata": {
        "id": "vWeJI9rampG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Here"
      ],
      "metadata": {
        "id": "SDSlFLY3WB-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_masks(arrays):\n",
        "    if len(arrays) == 0:\n",
        "        return np.zeros((224, 224))\n",
        "        \n",
        "    final_array = arrays[0]\n",
        "    for array in arrays[1:]:\n",
        "        final_array = np.maximum(final_array, array)\n",
        "        \n",
        "    return final_array"
      ],
      "metadata": {
        "id": "iYP6_5LYj0hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle, Polygon\n",
        "def evaluate(model, val_loader, device, epoch):\n",
        "  # mean_chest = [0.5240804197105211, 0.5240804197105211, 0.5240804197105211]\n",
        "  # std_chest = [0.17148634738092733, 0.17148634738092733, 0.17148634738092733]\n",
        "  mean_chest = [0.485, 0.456, 0.406]\n",
        "  std_chest = [0.229, 0.224, 0.225]\n",
        "  #[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "  TP_epoch = 0\n",
        "  FP_epoch = 0\n",
        "  TN_epoch = 0\n",
        "  FN_epoch = 0\n",
        "  counter_for_visuals = True \n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "      model.eval()\n",
        "      image_batch = images.to(device)\n",
        "      #target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "      predictions = model(image_batch)\n",
        "      #indices_of_images = [0,1,2,3,4,5,6,7]\n",
        "\n",
        "      if((counter_for_visuals == True) and (epoch % 2 == 0)):\n",
        "        counter_row = 0\n",
        "        counter_column = 0\n",
        "        fig, ax = plt.subplots(2, 4, figsize=(48, 24))\n",
        "        fig_m, ax_m = plt.subplots(2, 4, figsize=(48, 24))\n",
        "        #indices_of_images = random.sample(range(0, 15), 8)\n",
        "        indices_of_images = [0,2,4,6,8,10,12,14]\n",
        "\n",
        "        for img_trg_index in indices_of_images:\n",
        "          box_pred = list(predictions[img_trg_index]['boxes'])\n",
        "          box_actual = list(targets[img_trg_index]['boxes'])\n",
        "          mask_pred = list(predictions[img_trg_index]['masks'])\n",
        "          mask_actual = list(targets[img_trg_index]['masks'])\n",
        "          mask_actual_polys = list(targets[img_trg_index]['polys'])\n",
        "\n",
        "          actual_image = images[img_trg_index]\n",
        "          image_numpy = (actual_image.detach().cpu()).numpy()\n",
        "          actual_denormalized_image = denormalize_image(image_numpy, mean_chest, std_chest)\n",
        "\n",
        "          ax[counter_row, counter_column].imshow(actual_denormalized_image)\n",
        "          ax_m[counter_row, counter_column].imshow(actual_denormalized_image)\n",
        "\n",
        "          mask_actual_arrs = []\n",
        "          \n",
        "          for i in mask_actual:\n",
        "            tmp = i.numpy()\n",
        "            temp_locs = np.where(tmp == 1)\n",
        "            temp_mask = np.zeros((224,224))\n",
        "            temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            mask_actual_arrs.append(temp_mask)\n",
        "\n",
        "          combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "          actual_mask_color = np.array([0, 0, 1, 0.4]) #Blue\n",
        "          actual_mask_rgb = np.zeros((224, 224, 4))\n",
        "          actual_mask_rgb[combined_mask_actual == 1] = actual_mask_color\n",
        "          ax_m[counter_row, counter_column].imshow(actual_mask_rgb)\n",
        "\n",
        "          mask_pred_arrs = []\n",
        "\n",
        "          for i in mask_pred:\n",
        "            tmp = i.detach().cpu()\n",
        "            tmp2 = (tmp[0]).numpy()\n",
        "            temp_locs = np.where(tmp2 > 0.6)\n",
        "            temp_mask = np.zeros((224, 224))\n",
        "            temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            mask_pred_arrs.append(temp_mask)\n",
        "            \n",
        "          combined_mask_predicted = combine_masks(mask_pred_arrs)\n",
        "          predicted_mask_color = np.array([1, 1, 0, 0.2]) #Yellow\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 4))\n",
        "          predicted_mask_rgb[combined_mask_predicted == 1] = predicted_mask_color\n",
        "          ax_m[counter_row, counter_column].imshow(predicted_mask_rgb)\n",
        "\n",
        "          for j in box_actual:\n",
        "            tmp = j.numpy()\n",
        "            tmp_rect = Rectangle((tmp[0], tmp[1]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "            #tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax[counter_row, counter_column].add_patch(tmp_rect)\n",
        "          for i in box_pred:\n",
        "            tmp = i.detach().cpu().numpy()\n",
        "            tmp_rect = Rectangle((tmp[0], tmp[1]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1, edgecolor='g', facecolor='none')\n",
        "            #tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1, edgecolor='b', facecolor='none')\n",
        "            ax[counter_row, counter_column].add_patch(tmp_rect)\n",
        "\n",
        "          counter_column += 1\n",
        "          if(counter_column > 3):\n",
        "            counter_row += 1\n",
        "            counter_column = 0\n",
        "\n",
        "        #image_dir = '/content/Boxes_Images_Resized/'\n",
        "        #image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masked_Images_through_Epochs/'\n",
        "        image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Images_Instance_Segmentation_3/'\n",
        "        temp_filename = image_dir + 'Epoch_' + str(epoch) + '_BBox_Preds_BLUE_BBox_Actual_RED.png'\n",
        "        temp_filename_m = image_dir + 'Epoch_' + str(epoch) + '_Mask_Preds_BLUE_Mask_Actual_RED.png'\n",
        "        temp_title = 'Epoch ' + str(epoch) + ' BBox Predictions (Blue) vs. Actual BBox(Red)'\n",
        "        temp_title_m = 'Epoch ' + str(epoch) + ' Mask Predictions (Blue) vs. Actual Masks(Red)'\n",
        "        #plt.title(temp_title)\n",
        "        fig.suptitle(temp_title)\n",
        "        #plt.show()\n",
        "        fig_m.suptitle(temp_title_m)\n",
        "        plt.show()\n",
        "        fig.savefig(temp_filename)\n",
        "        fig_m.savefig(temp_filename_m)\n",
        "\n",
        "      counter_for_visuals = False\n",
        "\n",
        "      for i in range(len(targets)):\n",
        "        mask_pred = list(predictions[i]['masks'])\n",
        "        mask_actual = list((targets[i])['masks'])\n",
        "        mask_pred_arrs = []\n",
        "        mask_actual_arrs = []\n",
        "        #print(len(mask_pred))\n",
        "        #print(len(mask_actual))\n",
        "        #print(mask_pred[0].shape)\n",
        "        #print(mask_actual[0].shape)\n",
        "        if(len(mask_pred) == 0):\n",
        "          temp_mask_pred = np.zeros((224,224))\n",
        "          mask_pred_arrs.append(temp_mask_pred)\n",
        "        else:\n",
        "          for j in range(len(mask_pred)):\n",
        "            temp_pred = ((mask_pred[j].detach().cpu())[0]).numpy()\n",
        "            temp_locs_pred = np.where(temp_pred > 0.5)\n",
        "            temp_mask_pred = np.zeros((224,224))\n",
        "            temp_mask_pred[temp_locs_pred[0], temp_locs_pred[1]] = 1\n",
        "            mask_pred_arrs.append(temp_mask_pred)\n",
        "\n",
        "        if(len(mask_actual) == 0):\n",
        "          temp_mask_actual = np.zeros((224,224))\n",
        "          mask_actual_arrs.append(temp_mask_actual)\n",
        "        else:\n",
        "          for j in range(len(mask_actual)):\n",
        "            temp_actual = mask_actual[j].numpy()\n",
        "            temp_locs_actual = np.where(temp_actual == 1)\n",
        "            temp_mask_actual = np.zeros((224,224))\n",
        "            temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "            mask_actual_arrs.append(temp_mask_actual)\n",
        "\n",
        "        #print('HERE')\n",
        "        combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "        #print(combined_mask_pred)\n",
        "        #print(combined_mask_pred.shape)\n",
        "        #print('HERE2')\n",
        "        combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "        #print(combined_mask_actual)\n",
        "        #print(combined_mask_actual.shape)\n",
        "        #return\n",
        "        \n",
        "        TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "        TP_epoch += TP\n",
        "        FP_epoch += FP\n",
        "        TN_epoch += TN\n",
        "        FN_epoch += FN\n",
        "    \n",
        "    acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "    prec = precision(TP_epoch, FP_epoch)\n",
        "    rec = recall(TP_epoch, FN_epoch)\n",
        "    f1 = f1_score(prec, rec)\n",
        "    dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "    intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "    # print(acc)\n",
        "    # print(prec)\n",
        "    # print(rec)\n",
        "    # print(f1)\n",
        "    # print(dice)\n",
        "\n",
        "  return acc, prec, rec, f1, dice, intersection_over_union"
      ],
      "metadata": {
        "id": "cgeWrN4GWDoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Inferring on Validation - Normalized Based On ImageNet with 14 classes"
      ],
      "metadata": {
        "id": "cWFjg8w0PC1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4u0PgYbUPC1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "o3a8voAOPC1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 14\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "device = torch.device(device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "oA76CGMJPC1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix_elements(pred_mask, true_mask):\n",
        "    assert pred_mask.shape == true_mask.shape, \"Shape mismatch in input masks\"\n",
        "    \n",
        "    TP = np.sum((pred_mask == 1) & (true_mask == 1))\n",
        "    FP = np.sum((pred_mask == 1) & (true_mask == 0))\n",
        "    TN = np.sum((pred_mask == 0) & (true_mask == 0))\n",
        "    FN = np.sum((pred_mask == 0) & (true_mask == 1))\n",
        "    \n",
        "    return TP, FP, TN, FN"
      ],
      "metadata": {
        "id": "QqglpfnEGiQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(TP, FP, TN, FN):\n",
        "    return (TP + TN) / (TP + FP + TN + FN)\n",
        "\n",
        "def precision(TP, FP):\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "def recall(TP, FN):\n",
        "    return TP / (TP + FN)\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def dice_coefficient(TP, FP, FN):\n",
        "    return (2 * TP) / ((2 * TP) + FP + FN)\n",
        "\n",
        "def iou(TP, FP, FN):\n",
        "    return TP / (TP + FP + FN)"
      ],
      "metadata": {
        "id": "TzGZJEQeGjqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper setting #1"
      ],
      "metadata": {
        "id": "u1ylI1HHHqIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "l2_reg = 1e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "num_epochs = 40\n",
        "#num_epochs = 2\n",
        "\n",
        "epoch_losses_classifier = []\n",
        "epoch_losses_box_reg = []\n",
        "epoch_losses_objectness = []\n",
        "epoch_losses_rpn_box_reg = []\n",
        "epoch_losses_mask_reg = []\n",
        "\n",
        "acc_tr_epochs = []\n",
        "pre_tr_epochs = []\n",
        "rec_tr_epochs = []\n",
        "f1_tr_epochs = []\n",
        "dice_tr_epochs = []\n",
        "iou_tr_epochs = []\n",
        "\n",
        "acc_val_epochs = []\n",
        "pre_val_epochs = []\n",
        "rec_val_epochs = []\n",
        "f1_val_epochs = []\n",
        "dice_val_epochs = []\n",
        "iou_val_epochs = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses_classifier = []\n",
        "    losses_box_reg = []\n",
        "    losses_objectness = []\n",
        "    losses_rpn_box_reg = []\n",
        "    losses_mask_reg = []\n",
        "    counter_train = 0\n",
        "    temp_epoch = epoch + 1\n",
        "    \n",
        "    PATH = '/content/drive/MyDrive/ee641/Project_Datasets/Model_Checkpoints_1/model_epoch_' + str(temp_epoch) + '.pth'\n",
        "    \n",
        "    #acc, prec, rec, f1, dice, intersection_over_union = evaluate(model, val_loader, device, temp_epoch)\n",
        "    #break\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        model.train()\n",
        "\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        loss_classifier = outputs['loss_classifier']\n",
        "        loss_box_reg = outputs['loss_box_reg']\n",
        "        loss_objectness = outputs['loss_objectness']\n",
        "        loss_rpn_box_reg = outputs['loss_rpn_box_reg']\n",
        "        loss_mask_reg = outputs['loss_mask']\n",
        "\n",
        "        losses_classifier.append(loss_classifier.item())\n",
        "        losses_box_reg.append(loss_box_reg.item())\n",
        "        losses_objectness.append(loss_objectness.item())\n",
        "        losses_rpn_box_reg.append(loss_rpn_box_reg.item())\n",
        "        losses_mask_reg.append(loss_mask_reg.item())\n",
        "\n",
        "        combined_loss = loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg + loss_mask_reg\n",
        "\n",
        "        combined_loss.backward()\n",
        "        optimizer.step()\n",
        "        if(counter_train % 10 == 0):\n",
        "          print(counter_train*25)\n",
        "        counter_train = counter_train + 1\n",
        "    \n",
        "    avg_clss_loss = np.mean(losses_classifier)\n",
        "    avg_box_reg_loss = np.mean(losses_box_reg)\n",
        "    avg_objectness_loss = np.mean(losses_objectness)\n",
        "    avg_rpn_box_reg_loss = np.mean(losses_rpn_box_reg)\n",
        "    avg_mask_reg_loss = np.mean(losses_mask_reg)\n",
        "\n",
        "    epoch_losses_classifier.append(avg_clss_loss)\n",
        "    epoch_losses_box_reg.append(avg_box_reg_loss)\n",
        "    epoch_losses_objectness.append(avg_objectness_loss)\n",
        "    epoch_losses_rpn_box_reg.append(avg_rpn_box_reg_loss)\n",
        "    epoch_losses_mask_reg.append(avg_mask_reg_loss)\n",
        "\n",
        "    print('Training Negative Log-Likelihood Classification Loss in Epoch ', temp_epoch, ': ', avg_clss_loss)\n",
        "    print('Training Final Regression Loss for predicted Bounding Box Coordinates in Epoch ', temp_epoch, ': ', avg_box_reg_loss)\n",
        "    print('Training Binary Cross-Entropy Loss for Object/Not Object for RPN Network in Epoch ', temp_epoch, ': ', avg_objectness_loss)\n",
        "    print('Training Regression Loss for RPN Network Box Coordinates in Epoch ', temp_epoch, ': ', avg_rpn_box_reg_loss)\n",
        "    print('Training Regression Loss for Mask Polygon Coordinates in Epoch ', temp_epoch, ': ', avg_mask_reg_loss)\n",
        "    print('\\n')\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': temp_epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss_classifier': loss_classifier,\n",
        "            'loss_box_reg': loss_box_reg,\n",
        "            'loss_objectness': loss_objectness,\n",
        "            'loss_rpn_box_reg': loss_rpn_box_reg,\n",
        "            'loss_mask': loss_mask_reg\n",
        "            }, PATH)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      counter_eval = 0\n",
        "      TP_epoch = 0\n",
        "      FP_epoch = 0\n",
        "      TN_epoch = 0\n",
        "      FN_epoch = 0\n",
        "      for images, targets in train_loader:\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        # for i in range(len(targets_off_device)):\n",
        "        #   mask_pred = list((outputs[i])['masks'])\n",
        "        #   mask_actual = list((targets_off_device[i])['masks'])\n",
        "              \n",
        "        #   print(\"mask_pred length:\", len(mask_pred))\n",
        "        #   print(\"mask_actual length:\", len(mask_actual))\n",
        "        # continue\n",
        "\n",
        "        for i in range(len(targets_off_device)):\n",
        "          mask_pred = list((outputs[i])['masks'])\n",
        "          mask_actual = list((targets_off_device[i])['masks'])\n",
        "          mask_pred_arrs = []\n",
        "          mask_actual_arrs = []\n",
        "\n",
        "          if(len(mask_pred) == 0):\n",
        "            temp_mask_pred = np.zeros((224,224))\n",
        "            mask_pred_arrs.append(temp_mask_pred)\n",
        "          else:\n",
        "            for j in range(len(mask_pred)):\n",
        "              temp_pred = ((mask_pred[j].detach().cpu())[0]).numpy()\n",
        "              temp_locs_pred = np.where(temp_pred > 0.5)\n",
        "              temp_mask_pred = np.zeros((224,224))\n",
        "              temp_mask_pred[temp_locs_pred[0], temp_locs_pred[1]] = 1\n",
        "              mask_pred_arrs.append(temp_mask_pred)\n",
        "\n",
        "          if(len(mask_actual) == 0):\n",
        "            temp_mask_actual = np.zeros((224,224))\n",
        "            mask_actual_arrs.append(temp_mask_pred)  \n",
        "          else:\n",
        "            for j in range(len(mask_actual)):\n",
        "              temp_actual = mask_actual[j].numpy()\n",
        "              temp_locs_actual = np.where(temp_actual == 1)\n",
        "              temp_mask_actual = np.zeros((224,224))\n",
        "              temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "              mask_actual_arrs.append(temp_mask_actual)\n",
        "          \n",
        "          combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "          combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "\n",
        "\n",
        "          TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "          TP_epoch += TP\n",
        "          FP_epoch += FP\n",
        "          TN_epoch += TN\n",
        "          FN_epoch += FN\n",
        "        counter_eval += 1\n",
        "        if(counter_eval*batch_size >= 500):\n",
        "          break\n",
        "    acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "    prec = precision(TP_epoch, FP_epoch)\n",
        "    rec = recall(TP_epoch, FN_epoch)\n",
        "    f1 = f1_score(prec, rec)\n",
        "    dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "    intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "\n",
        "    # VALIDATE\n",
        "    model.eval()\n",
        "    acc_val, prec_val, rec_val, f1_val, dice_val, intersection_over_union_val = evaluate(model, val_loader, device, temp_epoch)\n",
        "    print('Training Mask Accuracy in Epoch ', temp_epoch, ': ', acc)\n",
        "    print('Training Mask Precision in Epoch ', temp_epoch, ': ', prec)\n",
        "    print('Training Mask Recall in Epoch ', temp_epoch, ': ', rec)\n",
        "    print('Training Mask F1-Score in Epoch ', temp_epoch, ': ', f1)\n",
        "    print('Training DICE Score in Epoch ', temp_epoch, ': ', dice)\n",
        "    print('Training Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union)\n",
        "    print('\\n')\n",
        "    print('Validation Mask Accuracy in Epoch ', temp_epoch, ': ', acc_val)\n",
        "    print('Validation Mask Precision in Epoch ', temp_epoch, ': ', prec_val)\n",
        "    print('Validation Mask Recall in Epoch ', temp_epoch, ': ', rec_val)\n",
        "    print('Validation Mask F1-Score in Epoch ', temp_epoch, ': ', f1_val)\n",
        "    print('Validation DICE Score in Epoch ', temp_epoch, ': ', dice_val)\n",
        "    print('Validation Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union_val)\n",
        "    print('\\n')\n",
        "\n",
        "    acc_tr_epochs.append(acc)\n",
        "    pre_tr_epochs.append(prec)\n",
        "    rec_tr_epochs.append(rec)\n",
        "    f1_tr_epochs.append(f1)\n",
        "    dice_tr_epochs.append(dice)\n",
        "    iou_tr_epochs.append(intersection_over_union)\n",
        "\n",
        "    acc_val_epochs.append(acc_val)\n",
        "    pre_val_epochs.append(prec_val)\n",
        "    rec_val_epochs.append(rec_val)\n",
        "    f1_val_epochs.append(f1_val)\n",
        "    dice_val_epochs.append(dice_val)\n",
        "    iou_val_epochs.append(intersection_over_union_val)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "scores_dict = {}\n",
        "\n",
        "scores_dict['acc_tr'] = acc_tr_epochs\n",
        "scores_dict['pre_tr'] = pre_tr_epochs\n",
        "scores_dict['rec_tr'] = rec_tr_epochs\n",
        "scores_dict['f1_tr'] = f1_tr_epochs\n",
        "scores_dict['dice_tr'] = dice_tr_epochs\n",
        "scores_dict['iou_tr'] = iou_tr_epochs\n",
        "\n",
        "scores_dict['acc_val'] = acc_val_epochs\n",
        "scores_dict['pre_val'] = pre_val_epochs\n",
        "scores_dict['rec_val'] = rec_val_epochs\n",
        "scores_dict['f1_val'] = f1_val_epochs\n",
        "scores_dict['dice_val'] = dice_val_epochs\n",
        "scores_dict['iou_val'] = iou_val_epochs\n",
        "    \n",
        "\n",
        "plotter(epoch_losses_classifier, epoch_losses_box_reg, epoch_losses_objectness, epoch_losses_rpn_box_reg, epoch_losses_mask_reg)\n",
        "print('\\n')\n",
        "plotter_2(scores_dict)"
      ],
      "metadata": {
        "id": "EoQvMa6_PC1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotter(epoch_losses_classifier, epoch_losses_box_reg, epoch_losses_objectness, epoch_losses_rpn_box_reg, epoch_losses_mask_reg)\n",
        "print('\\n')\n",
        "plotter_2(scores_dict)"
      ],
      "metadata": {
        "id": "5OHxfG0Wqllq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper setting #2"
      ],
      "metadata": {
        "id": "hxj-kFZSH1gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "l2_reg = 1e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "num_epochs = 50\n",
        "#num_epochs = 2\n",
        "\n",
        "epoch_losses_classifier = []\n",
        "epoch_losses_box_reg = []\n",
        "epoch_losses_objectness = []\n",
        "epoch_losses_rpn_box_reg = []\n",
        "epoch_losses_mask_reg = []\n",
        "\n",
        "acc_tr_epochs = []\n",
        "pre_tr_epochs = []\n",
        "rec_tr_epochs = []\n",
        "f1_tr_epochs = []\n",
        "dice_tr_epochs = []\n",
        "iou_tr_epochs = []\n",
        "\n",
        "acc_val_epochs = []\n",
        "pre_val_epochs = []\n",
        "rec_val_epochs = []\n",
        "f1_val_epochs = []\n",
        "dice_val_epochs = []\n",
        "iou_val_epochs = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses_classifier = []\n",
        "    losses_box_reg = []\n",
        "    losses_objectness = []\n",
        "    losses_rpn_box_reg = []\n",
        "    losses_mask_reg = []\n",
        "    counter_train = 0\n",
        "    temp_epoch = epoch + 1\n",
        "    \n",
        "    PATH = '/content/drive/MyDrive/ee641/Project_Datasets/Model_Checkpoints_2/model_epoch_' + str(temp_epoch) + '.pth'\n",
        "    \n",
        "    #acc, prec, rec, f1, dice, intersection_over_union = evaluate(model, val_loader, device, temp_epoch)\n",
        "    #break\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        model.train()\n",
        "\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        loss_classifier = outputs['loss_classifier']\n",
        "        loss_box_reg = outputs['loss_box_reg']\n",
        "        loss_objectness = outputs['loss_objectness']\n",
        "        loss_rpn_box_reg = outputs['loss_rpn_box_reg']\n",
        "        loss_mask_reg = outputs['loss_mask']\n",
        "\n",
        "        losses_classifier.append(loss_classifier.item())\n",
        "        losses_box_reg.append(loss_box_reg.item())\n",
        "        losses_objectness.append(loss_objectness.item())\n",
        "        losses_rpn_box_reg.append(loss_rpn_box_reg.item())\n",
        "        losses_mask_reg.append(loss_mask_reg.item())\n",
        "\n",
        "        combined_loss = loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg + loss_mask_reg\n",
        "\n",
        "        combined_loss.backward()\n",
        "        optimizer.step()\n",
        "        if(counter_train % 10 == 0):\n",
        "          print(counter_train*25)\n",
        "        counter_train = counter_train + 1\n",
        "    \n",
        "    avg_clss_loss = np.mean(losses_classifier)\n",
        "    avg_box_reg_loss = np.mean(losses_box_reg)\n",
        "    avg_objectness_loss = np.mean(losses_objectness)\n",
        "    avg_rpn_box_reg_loss = np.mean(losses_rpn_box_reg)\n",
        "    avg_mask_reg_loss = np.mean(losses_mask_reg)\n",
        "\n",
        "    epoch_losses_classifier.append(avg_clss_loss)\n",
        "    epoch_losses_box_reg.append(avg_box_reg_loss)\n",
        "    epoch_losses_objectness.append(avg_objectness_loss)\n",
        "    epoch_losses_rpn_box_reg.append(avg_rpn_box_reg_loss)\n",
        "    epoch_losses_mask_reg.append(avg_mask_reg_loss)\n",
        "\n",
        "    print('Training Negative Log-Likelihood Classification Loss in Epoch ', temp_epoch, ': ', avg_clss_loss)\n",
        "    print('Training Final Regression Loss for predicted Bounding Box Coordinates in Epoch ', temp_epoch, ': ', avg_box_reg_loss)\n",
        "    print('Training Binary Cross-Entropy Loss for Object/Not Object for RPN Network in Epoch ', temp_epoch, ': ', avg_objectness_loss)\n",
        "    print('Training Regression Loss for RPN Network Box Coordinates in Epoch ', temp_epoch, ': ', avg_rpn_box_reg_loss)\n",
        "    print('Training Regression Loss for Mask Polygon Coordinates in Epoch ', temp_epoch, ': ', avg_mask_reg_loss)\n",
        "    print('\\n')\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': temp_epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss_classifier': loss_classifier,\n",
        "            'loss_box_reg': loss_box_reg,\n",
        "            'loss_objectness': loss_objectness,\n",
        "            'loss_rpn_box_reg': loss_rpn_box_reg,\n",
        "            'loss_mask': loss_mask_reg\n",
        "            }, PATH)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      counter_eval = 0\n",
        "      TP_epoch = 0\n",
        "      FP_epoch = 0\n",
        "      TN_epoch = 0\n",
        "      FN_epoch = 0\n",
        "      for images, targets in train_loader:\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        # for i in range(len(targets_off_device)):\n",
        "        #   mask_pred = list((outputs[i])['masks'])\n",
        "        #   mask_actual = list((targets_off_device[i])['masks'])\n",
        "              \n",
        "        #   print(\"mask_pred length:\", len(mask_pred))\n",
        "        #   print(\"mask_actual length:\", len(mask_actual))\n",
        "        # continue\n",
        "\n",
        "        for i in range(len(targets_off_device)):\n",
        "          mask_pred = list((outputs[i])['masks'])\n",
        "          mask_actual = list((targets_off_device[i])['masks'])\n",
        "          mask_pred_arrs = []\n",
        "          mask_actual_arrs = []\n",
        "\n",
        "          if(len(mask_pred) == 0):\n",
        "            temp_mask_pred = np.zeros((224,224))\n",
        "            mask_pred_arrs.append(temp_mask_pred)\n",
        "          else:\n",
        "            for j in range(len(mask_pred)):\n",
        "              temp_pred = ((mask_pred[j].detach().cpu())[0]).numpy()\n",
        "              temp_locs_pred = np.where(temp_pred > 0.5)\n",
        "              temp_mask_pred = np.zeros((224,224))\n",
        "              temp_mask_pred[temp_locs_pred[0], temp_locs_pred[1]] = 1\n",
        "              mask_pred_arrs.append(temp_mask_pred)\n",
        "\n",
        "          if(len(mask_actual) == 0):\n",
        "            temp_mask_actual = np.zeros((224,224))\n",
        "            mask_actual_arrs.append(temp_mask_pred)  \n",
        "          else:\n",
        "            for j in range(len(mask_actual)):\n",
        "              temp_actual = mask_actual[j].numpy()\n",
        "              temp_locs_actual = np.where(temp_actual == 1)\n",
        "              temp_mask_actual = np.zeros((224,224))\n",
        "              temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "              mask_actual_arrs.append(temp_mask_actual)\n",
        "          \n",
        "          combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "          combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "\n",
        "\n",
        "          TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "          TP_epoch += TP\n",
        "          FP_epoch += FP\n",
        "          TN_epoch += TN\n",
        "          FN_epoch += FN\n",
        "        counter_eval += 1\n",
        "        if(counter_eval*batch_size >= 750):\n",
        "          break\n",
        "    acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "    prec = precision(TP_epoch, FP_epoch)\n",
        "    rec = recall(TP_epoch, FN_epoch)\n",
        "    f1 = f1_score(prec, rec)\n",
        "    dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "    intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "\n",
        "    # VALIDATE\n",
        "    model.eval()\n",
        "    acc_val, prec_val, rec_val, f1_val, dice_val, intersection_over_union_val = evaluate(model, val_loader, device, temp_epoch)\n",
        "    print('Training Mask Accuracy in Epoch ', temp_epoch, ': ', acc)\n",
        "    print('Training Mask Precision in Epoch ', temp_epoch, ': ', prec)\n",
        "    print('Training Mask Recall in Epoch ', temp_epoch, ': ', rec)\n",
        "    print('Training Mask F1-Score in Epoch ', temp_epoch, ': ', f1)\n",
        "    print('Training DICE Score in Epoch ', temp_epoch, ': ', dice)\n",
        "    print('Training Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union)\n",
        "    print('\\n')\n",
        "    print('Validation Mask Accuracy in Epoch ', temp_epoch, ': ', acc_val)\n",
        "    print('Validation Mask Precision in Epoch ', temp_epoch, ': ', prec_val)\n",
        "    print('Validation Mask Recall in Epoch ', temp_epoch, ': ', rec_val)\n",
        "    print('Validation Mask F1-Score in Epoch ', temp_epoch, ': ', f1_val)\n",
        "    print('Validation DICE Score in Epoch ', temp_epoch, ': ', dice_val)\n",
        "    print('Validation Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union_val)\n",
        "    print('\\n')\n",
        "\n",
        "    acc_tr_epochs.append(acc)\n",
        "    pre_tr_epochs.append(prec)\n",
        "    rec_tr_epochs.append(rec)\n",
        "    f1_tr_epochs.append(f1)\n",
        "    dice_tr_epochs.append(dice)\n",
        "    iou_tr_epochs.append(intersection_over_union)\n",
        "\n",
        "    acc_val_epochs.append(acc_val)\n",
        "    pre_val_epochs.append(prec_val)\n",
        "    rec_val_epochs.append(rec_val)\n",
        "    f1_val_epochs.append(f1_val)\n",
        "    dice_val_epochs.append(dice_val)\n",
        "    iou_val_epochs.append(intersection_over_union_val)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "scores_dict = {}\n",
        "\n",
        "scores_dict['acc_tr'] = acc_tr_epochs\n",
        "scores_dict['pre_tr'] = pre_tr_epochs\n",
        "scores_dict['rec_tr'] = rec_tr_epochs\n",
        "scores_dict['f1_tr'] = f1_tr_epochs\n",
        "scores_dict['dice_tr'] = dice_tr_epochs\n",
        "scores_dict['iou_tr'] = iou_tr_epochs\n",
        "\n",
        "scores_dict['acc_val'] = acc_val_epochs\n",
        "scores_dict['pre_val'] = pre_val_epochs\n",
        "scores_dict['rec_val'] = rec_val_epochs\n",
        "scores_dict['f1_val'] = f1_val_epochs\n",
        "scores_dict['dice_val'] = dice_val_epochs\n",
        "scores_dict['iou_val'] = iou_val_epochs\n",
        "    \n",
        "\n",
        "plotter(epoch_losses_classifier, epoch_losses_box_reg, epoch_losses_objectness, epoch_losses_rpn_box_reg, epoch_losses_mask_reg)\n",
        "print('\\n')\n",
        "plotter_2(scores_dict)"
      ],
      "metadata": {
        "id": "CQAqkOX6H1gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper setting #3"
      ],
      "metadata": {
        "id": "Vbj9BOwT7eYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "l2_reg = 5 * 1e-5\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9,  weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 50\n",
        "#num_epochs = 2\n",
        "\n",
        "epoch_losses_classifier = []\n",
        "epoch_losses_box_reg = []\n",
        "epoch_losses_objectness = []\n",
        "epoch_losses_rpn_box_reg = []\n",
        "epoch_losses_mask_reg = []\n",
        "\n",
        "acc_tr_epochs = []\n",
        "pre_tr_epochs = []\n",
        "rec_tr_epochs = []\n",
        "f1_tr_epochs = []\n",
        "dice_tr_epochs = []\n",
        "iou_tr_epochs = []\n",
        "\n",
        "acc_val_epochs = []\n",
        "pre_val_epochs = []\n",
        "rec_val_epochs = []\n",
        "f1_val_epochs = []\n",
        "dice_val_epochs = []\n",
        "iou_val_epochs = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses_classifier = []\n",
        "    losses_box_reg = []\n",
        "    losses_objectness = []\n",
        "    losses_rpn_box_reg = []\n",
        "    losses_mask_reg = []\n",
        "    counter_train = 0\n",
        "    temp_epoch = epoch + 1\n",
        "    \n",
        "    PATH = '/content/drive/MyDrive/ee641/Project_Datasets/Model_Checkpoints_3/model_epoch_' + str(temp_epoch) + '.pth'\n",
        "    \n",
        "    #acc, prec, rec, f1, dice, intersection_over_union = evaluate(model, val_loader, device, temp_epoch)\n",
        "    #break\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        model.train()\n",
        "\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        loss_classifier = outputs['loss_classifier']\n",
        "        loss_box_reg = outputs['loss_box_reg']\n",
        "        loss_objectness = outputs['loss_objectness']\n",
        "        loss_rpn_box_reg = outputs['loss_rpn_box_reg']\n",
        "        loss_mask_reg = outputs['loss_mask']\n",
        "\n",
        "        losses_classifier.append(loss_classifier.item())\n",
        "        losses_box_reg.append(loss_box_reg.item())\n",
        "        losses_objectness.append(loss_objectness.item())\n",
        "        losses_rpn_box_reg.append(loss_rpn_box_reg.item())\n",
        "        losses_mask_reg.append(loss_mask_reg.item())\n",
        "\n",
        "        combined_loss = loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg + loss_mask_reg\n",
        "\n",
        "        combined_loss.backward()\n",
        "        optimizer.step()\n",
        "        if(counter_train % 10 == 0):\n",
        "          print(counter_train*25)\n",
        "        counter_train = counter_train + 1\n",
        "    \n",
        "    avg_clss_loss = np.mean(losses_classifier)\n",
        "    avg_box_reg_loss = np.mean(losses_box_reg)\n",
        "    avg_objectness_loss = np.mean(losses_objectness)\n",
        "    avg_rpn_box_reg_loss = np.mean(losses_rpn_box_reg)\n",
        "    avg_mask_reg_loss = np.mean(losses_mask_reg)\n",
        "\n",
        "    epoch_losses_classifier.append(avg_clss_loss)\n",
        "    epoch_losses_box_reg.append(avg_box_reg_loss)\n",
        "    epoch_losses_objectness.append(avg_objectness_loss)\n",
        "    epoch_losses_rpn_box_reg.append(avg_rpn_box_reg_loss)\n",
        "    epoch_losses_mask_reg.append(avg_mask_reg_loss)\n",
        "\n",
        "    print('Training Negative Log-Likelihood Classification Loss in Epoch ', temp_epoch, ': ', avg_clss_loss)\n",
        "    print('Training Final Regression Loss for predicted Bounding Box Coordinates in Epoch ', temp_epoch, ': ', avg_box_reg_loss)\n",
        "    print('Training Binary Cross-Entropy Loss for Object/Not Object for RPN Network in Epoch ', temp_epoch, ': ', avg_objectness_loss)\n",
        "    print('Training Regression Loss for RPN Network Box Coordinates in Epoch ', temp_epoch, ': ', avg_rpn_box_reg_loss)\n",
        "    print('Training Regression Loss for Mask Polygon Coordinates in Epoch ', temp_epoch, ': ', avg_mask_reg_loss)\n",
        "    print('\\n')\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': temp_epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss_classifier': loss_classifier,\n",
        "            'loss_box_reg': loss_box_reg,\n",
        "            'loss_objectness': loss_objectness,\n",
        "            'loss_rpn_box_reg': loss_rpn_box_reg,\n",
        "            'loss_mask': loss_mask_reg\n",
        "            }, PATH)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      counter_eval = 0\n",
        "      TP_epoch = 0\n",
        "      FP_epoch = 0\n",
        "      TN_epoch = 0\n",
        "      FN_epoch = 0\n",
        "      for images, targets in train_loader:\n",
        "        image_batch = images.to(device)\n",
        "        targets_off_device = targets\n",
        "        target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "        outputs = model(image_batch, target_batch)\n",
        "\n",
        "        # for i in range(len(targets_off_device)):\n",
        "        #   mask_pred = list((outputs[i])['masks'])\n",
        "        #   mask_actual = list((targets_off_device[i])['masks'])\n",
        "              \n",
        "        #   print(\"mask_pred length:\", len(mask_pred))\n",
        "        #   print(\"mask_actual length:\", len(mask_actual))\n",
        "        # continue\n",
        "\n",
        "        for i in range(len(targets_off_device)):\n",
        "          mask_pred = list((outputs[i])['masks'])\n",
        "          mask_actual = list((targets_off_device[i])['masks'])\n",
        "          mask_pred_arrs = []\n",
        "          mask_actual_arrs = []\n",
        "\n",
        "          if(len(mask_pred) == 0):\n",
        "            temp_mask_pred = np.zeros((224,224))\n",
        "            mask_pred_arrs.append(temp_mask_pred)\n",
        "          else:\n",
        "            for j in range(len(mask_pred)):\n",
        "              temp_pred = ((mask_pred[j].detach().cpu())[0]).numpy()\n",
        "              temp_locs_pred = np.where(temp_pred > 0.5)\n",
        "              temp_mask_pred = np.zeros((224,224))\n",
        "              temp_mask_pred[temp_locs_pred[0], temp_locs_pred[1]] = 1\n",
        "              mask_pred_arrs.append(temp_mask_pred)\n",
        "\n",
        "          if(len(mask_actual) == 0):\n",
        "            temp_mask_actual = np.zeros((224,224))\n",
        "            mask_actual_arrs.append(temp_mask_pred)  \n",
        "          else:\n",
        "            for j in range(len(mask_actual)):\n",
        "              temp_actual = mask_actual[j].numpy()\n",
        "              temp_locs_actual = np.where(temp_actual == 1)\n",
        "              temp_mask_actual = np.zeros((224,224))\n",
        "              temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "              mask_actual_arrs.append(temp_mask_actual)\n",
        "          \n",
        "          combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "          combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "\n",
        "\n",
        "          TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "          TP_epoch += TP\n",
        "          FP_epoch += FP\n",
        "          TN_epoch += TN\n",
        "          FN_epoch += FN\n",
        "        counter_eval += 1\n",
        "        if(counter_eval*batch_size >= 750):\n",
        "          break\n",
        "    acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "    prec = precision(TP_epoch, FP_epoch)\n",
        "    rec = recall(TP_epoch, FN_epoch)\n",
        "    f1 = f1_score(prec, rec)\n",
        "    dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "    intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "\n",
        "    # VALIDATE\n",
        "    model.eval()\n",
        "    acc_val, prec_val, rec_val, f1_val, dice_val, intersection_over_union_val = evaluate(model, val_loader, device, temp_epoch)\n",
        "    print('Training Mask Accuracy in Epoch ', temp_epoch, ': ', acc)\n",
        "    print('Training Mask Precision in Epoch ', temp_epoch, ': ', prec)\n",
        "    print('Training Mask Recall in Epoch ', temp_epoch, ': ', rec)\n",
        "    print('Training Mask F1-Score in Epoch ', temp_epoch, ': ', f1)\n",
        "    print('Training DICE Score in Epoch ', temp_epoch, ': ', dice)\n",
        "    print('Training Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union)\n",
        "    print('\\n')\n",
        "    print('Validation Mask Accuracy in Epoch ', temp_epoch, ': ', acc_val)\n",
        "    print('Validation Mask Precision in Epoch ', temp_epoch, ': ', prec_val)\n",
        "    print('Validation Mask Recall in Epoch ', temp_epoch, ': ', rec_val)\n",
        "    print('Validation Mask F1-Score in Epoch ', temp_epoch, ': ', f1_val)\n",
        "    print('Validation DICE Score in Epoch ', temp_epoch, ': ', dice_val)\n",
        "    print('Validation Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union_val)\n",
        "    print('\\n')\n",
        "\n",
        "    acc_tr_epochs.append(acc)\n",
        "    pre_tr_epochs.append(prec)\n",
        "    rec_tr_epochs.append(rec)\n",
        "    f1_tr_epochs.append(f1)\n",
        "    dice_tr_epochs.append(dice)\n",
        "    iou_tr_epochs.append(intersection_over_union)\n",
        "\n",
        "    acc_val_epochs.append(acc_val)\n",
        "    pre_val_epochs.append(prec_val)\n",
        "    rec_val_epochs.append(rec_val)\n",
        "    f1_val_epochs.append(f1_val)\n",
        "    dice_val_epochs.append(dice_val)\n",
        "    iou_val_epochs.append(intersection_over_union_val)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "scores_dict = {}\n",
        "\n",
        "scores_dict['acc_tr'] = acc_tr_epochs\n",
        "scores_dict['pre_tr'] = pre_tr_epochs\n",
        "scores_dict['rec_tr'] = rec_tr_epochs\n",
        "scores_dict['f1_tr'] = f1_tr_epochs\n",
        "scores_dict['dice_tr'] = dice_tr_epochs\n",
        "scores_dict['iou_tr'] = iou_tr_epochs\n",
        "\n",
        "scores_dict['acc_val'] = acc_val_epochs\n",
        "scores_dict['pre_val'] = pre_val_epochs\n",
        "scores_dict['rec_val'] = rec_val_epochs\n",
        "scores_dict['f1_val'] = f1_val_epochs\n",
        "scores_dict['dice_val'] = dice_val_epochs\n",
        "scores_dict['iou_val'] = iou_val_epochs\n",
        "    \n",
        "\n",
        "plotter(epoch_losses_classifier, epoch_losses_box_reg, epoch_losses_objectness, epoch_losses_rpn_box_reg, epoch_losses_mask_reg)\n",
        "print('\\n')\n",
        "plotter_2(scores_dict)"
      ],
      "metadata": {
        "id": "yuVP07M47eYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GnTyfgutXMaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MSA_MHAAXWkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking Strategies Performance "
      ],
      "metadata": {
        "id": "zb4Wp2NsZaIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_tr_epochs_05 = []\n",
        "pre_tr_epochs_05 = []\n",
        "rec_tr_epochs_05 = []\n",
        "f1_tr_epochs_05 = []\n",
        "dice_tr_epochs_05 = []\n",
        "iou_tr_epochs_05 = []\n",
        "\n",
        "acc_val_epochs_05 = []\n",
        "pre_val_epochs_05 = []\n",
        "rec_val_epochs_05 = []\n",
        "f1_val_epochs_05 = []\n",
        "dice_val_epochs_05 = []\n",
        "iou_val_epochs_05 = []\n",
        "\n",
        "acc_tr_epochs_06 = []\n",
        "pre_tr_epochs_06 = []\n",
        "rec_tr_epochs_06 = []\n",
        "f1_tr_epochs_06 = []\n",
        "dice_tr_epochs_06 = []\n",
        "iou_tr_epochs_06 = []\n",
        "\n",
        "acc_val_epochs_06 = []\n",
        "pre_val_epochs_06 = []\n",
        "rec_val_epochs_06 = []\n",
        "f1_val_epochs_06 = []\n",
        "dice_val_epochs_06 = []\n",
        "iou_val_epochs_06 = []\n",
        "\n",
        "acc_tr_epochs_07 = []\n",
        "pre_tr_epochs_07 = []\n",
        "rec_tr_epochs_07 = []\n",
        "f1_tr_epochs_07 = []\n",
        "dice_tr_epochs_07 = []\n",
        "iou_tr_epochs_07 = []\n",
        "\n",
        "acc_val_epochs_07 = []\n",
        "pre_val_epochs_07 = []\n",
        "rec_val_epochs_07 = []\n",
        "f1_val_epochs_07 = []\n",
        "dice_val_epochs_07 = []\n",
        "iou_val_epochs_07 = []\n",
        "\n",
        "acc_tr_epochs_08 = []\n",
        "pre_tr_epochs_08 = []\n",
        "rec_tr_epochs_08 = []\n",
        "f1_tr_epochs_08 = []\n",
        "dice_tr_epochs_08 = []\n",
        "iou_tr_epochs_08 = []\n",
        "\n",
        "acc_val_epochs_08 = []\n",
        "pre_val_epochs_08 = []\n",
        "rec_val_epochs_08 = []\n",
        "f1_val_epochs_08 = []\n",
        "dice_val_epochs_08 = []\n",
        "iou_val_epochs_08 = []\n",
        "\n",
        "acc_tr_epochs_otsu = []\n",
        "pre_tr_epochs_otsu = []\n",
        "rec_tr_epochs_otsu = []\n",
        "f1_tr_epochs_otsu = []\n",
        "dice_tr_epochs_otsu = []\n",
        "iou_tr_epochs_otsu = []\n",
        "\n",
        "acc_val_epochs_otsu = []\n",
        "pre_val_epochs_otsu = []\n",
        "rec_val_epochs_otsu = []\n",
        "f1_val_epochs_otsu = []\n",
        "dice_val_epochs_otsu = []\n",
        "iou_val_epochs_otsu = []"
      ],
      "metadata": {
        "id": "L2oUgnRNJd19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2], [3,4]])\n",
        "b = np.array([[1,1], [3,2]])\n",
        "c = np.zeros((2,2))\n",
        "c[a > b] = 1\n",
        "print(c)"
      ],
      "metadata": {
        "id": "HQI2nQ2Lbb6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'mask_prob' is the predicted probability map output from your model.\n",
        "# It should be a 2D numpy array.\n",
        "mask_prob = np.array([[0.45, 0.2, 0.15], [0.1, 0.75, 0.24]])\n",
        "# Convert probabilities to a grayscale image in range [0, 255]\n",
        "mask_prob_uint8 = (mask_prob * 255).astype(np.uint8)\n",
        "print(mask_prob_uint8)\n",
        "\n",
        "# Apply Otsu's thresholding\n",
        "_, mask_otsu = cv2.threshold(mask_prob_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "print(mask_otsu)\n",
        "# Convert back to [0, 1] range if needed\n",
        "mask_otsu = mask_otsu.astype(np.uint8) / 255\n",
        "print(mask_otsu)"
      ],
      "metadata": {
        "id": "N2tyIBQ0bb6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle, Polygon\n",
        "def evaluate_masking(model, val_loader, device, epoch, mode=None, threshold = None):\n",
        "  # mean_chest = [0.5240804197105211, 0.5240804197105211, 0.5240804197105211]\n",
        "  # std_chest = [0.17148634738092733, 0.17148634738092733, 0.17148634738092733]\n",
        "  mean_chest = [0.485, 0.456, 0.406]\n",
        "  std_chest = [0.229, 0.224, 0.225]\n",
        "  #[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "  TP_epoch = 0\n",
        "  FP_epoch = 0\n",
        "  TN_epoch = 0\n",
        "  FN_epoch = 0\n",
        "  counter_for_visuals = True \n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "      model.eval()\n",
        "      image_batch = images.to(device)\n",
        "      #target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "      predictions = model(image_batch)\n",
        "      #indices_of_images = [0,1,2,3,4,5,6,7]\n",
        "\n",
        "      if((counter_for_visuals == True) and (epoch % 5 == 0)):\n",
        "        counter_row = 0\n",
        "        counter_column = 0\n",
        "        #fig, ax = plt.subplots(2, 4, figsize=(48, 24))\n",
        "        fig_m, ax_m = plt.subplots(2, 4, figsize=(48, 24))\n",
        "        #indices_of_images = random.sample(range(0, 15), 8)\n",
        "        indices_of_images = [0,2,4,6,8,10,12,14]\n",
        "\n",
        "        for img_trg_index in indices_of_images:\n",
        "          #box_pred = list(predictions[img_trg_index]['boxes'])\n",
        "          #box_actual = list(targets[img_trg_index]['boxes'])\n",
        "          mask_pred = list(predictions[img_trg_index]['masks'])\n",
        "          mask_actual = list(targets[img_trg_index]['masks'])\n",
        "          mask_actual_polys = list(targets[img_trg_index]['polys'])\n",
        "\n",
        "          actual_image = images[img_trg_index]\n",
        "          image_numpy = (actual_image.detach().cpu()).numpy()\n",
        "          actual_denormalized_image = denormalize_image(image_numpy, mean_chest, std_chest)\n",
        "\n",
        "          #ax[counter_row, counter_column].imshow(actual_denormalized_image)\n",
        "          ax_m[counter_row, counter_column].imshow(actual_denormalized_image)\n",
        "\n",
        "          mask_actual_arrs = []\n",
        "          \n",
        "          for i in mask_actual:\n",
        "            tmp = i.numpy()\n",
        "            temp_locs = np.where(tmp == 1)\n",
        "            temp_mask = np.zeros((224,224))\n",
        "            temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            mask_actual_arrs.append(temp_mask)\n",
        "\n",
        "          combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "          actual_mask_color = np.array([0, 0, 1, 0.4]) #Blue\n",
        "          actual_mask_rgb = np.zeros((224, 224, 4))\n",
        "          actual_mask_rgb[combined_mask_actual == 1] = actual_mask_color\n",
        "          ax_m[counter_row, counter_column].imshow(actual_mask_rgb)\n",
        "\n",
        "          mask_pred_arrs = []\n",
        "          \n",
        "          for i in mask_pred:\n",
        "            tmp = i.detach().cpu()\n",
        "            tmp2 = (tmp[0]).numpy()\n",
        "            temp_mask = np.zeros((224, 224))\n",
        "            if(mode == 'Threshold'):\n",
        "              temp_locs = np.where(tmp2 > threshold)\n",
        "              temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            else:\n",
        "              mask_prob_uint8 = (tmp2 * 255).astype(np.uint8)\n",
        "              _, mask_otsu = cv2.threshold(mask_prob_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "              mask_otsu = mask_otsu.astype(np.uint8) / 255\n",
        "              temp_locs = np.where(mask_otsu == 1)\n",
        "              temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            mask_pred_arrs.append(temp_mask)\n",
        "            \n",
        "          combined_mask_predicted = combine_masks(mask_pred_arrs)\n",
        "          predicted_mask_color = np.array([1, 1, 0, 0.2]) #Yellow\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 4))\n",
        "          predicted_mask_rgb[combined_mask_predicted == 1] = predicted_mask_color\n",
        "          ax_m[counter_row, counter_column].imshow(predicted_mask_rgb)\n",
        "\n",
        "          # for j in box_actual:\n",
        "          #   tmp = j.numpy()\n",
        "          #   tmp_rect = Rectangle((tmp[0], tmp[1]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "          #   #tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "          #   ax[counter_row, counter_column].add_patch(tmp_rect)\n",
        "          # for i in box_pred:\n",
        "          #   tmp = i.detach().cpu().numpy()\n",
        "          #   tmp_rect = Rectangle((tmp[0], tmp[1]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1, edgecolor='g', facecolor='none')\n",
        "          #   #tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1, edgecolor='b', facecolor='none')\n",
        "          #   ax[counter_row, counter_column].add_patch(tmp_rect)\n",
        "\n",
        "          counter_column += 1\n",
        "          if(counter_column > 3):\n",
        "            counter_row += 1\n",
        "            counter_column = 0\n",
        "\n",
        "        #image_dir = '/content/Boxes_Images_Resized/'\n",
        "        #image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masked_Images_through_Epochs/'\n",
        "        if(mode == 'Otsu'):\n",
        "          image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masking_Strategies_Best_Model_Otsu_Threshold/'\n",
        "          temp_title_m = 'Otsu Thresholding Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "        else:\n",
        "          if(threshold == 0.5):\n",
        "            image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masking_Strategies_Best_Model_05_Threshold/'\n",
        "            temp_title_m = '0.5 Thresholding Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "          elif(threshold == 0.6):\n",
        "            image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masking_Strategies_Best_Model_06_Threshold/'\n",
        "            temp_title_m = '0.6 Thresholding Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "          elif(threshold == 0.7):\n",
        "            image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masking_Strategies_Best_Model_07_Threshold/'\n",
        "            temp_title_m = '0.7 Thresholding Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "          else:\n",
        "            image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masking_Strategies_Best_Model_08_Threshold/'\n",
        "            temp_title_m = '0.8 Thresholding Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "\n",
        "        #image_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Images_Instance_Segmentation_3/'\n",
        "        #temp_filename = image_dir + 'Epoch_' + str(epoch) + '_BBox_Preds_BLUE_BBox_Actual_RED.png'\n",
        "        temp_filename_m = image_dir + 'Epoch_' + str(epoch) + '_Mask_Preds_YELLOW_Mask_Actual_BLUE.png'\n",
        "        #temp_title = 'Epoch ' + str(epoch) + ' BBox Predictions (Blue) vs. Actual BBox(Red)'\n",
        "        #temp_title_m = 'Epoch ' + str(epoch) + ' Mask Predictions (Yellow) vs. Actual Masks(Blue)'\n",
        "        print(temp_title_m)\n",
        "        #plt.title(temp_title)\n",
        "        #fig.suptitle(temp_title)\n",
        "        #plt.show()\n",
        "        fig_m.suptitle(temp_title_m)\n",
        "        plt.show()\n",
        "        #fig.savefig(temp_filename)\n",
        "        fig_m.savefig(temp_filename_m)\n",
        "\n",
        "      counter_for_visuals = False\n",
        "\n",
        "      for i in range(len(targets)):\n",
        "        mask_pred = list(predictions[i]['masks'])\n",
        "        mask_actual = list((targets[i])['masks'])\n",
        "        mask_pred_arrs = []\n",
        "        mask_actual_arrs = []\n",
        "        #print(len(mask_pred))\n",
        "        #print(len(mask_actual))\n",
        "        #print(mask_pred[0].shape)\n",
        "        #print(mask_actual[0].shape)\n",
        "        if(len(mask_pred) == 0):\n",
        "          temp_mask_pred = np.zeros((224,224))\n",
        "          mask_pred_arrs.append(temp_mask_pred)\n",
        "        else:\n",
        "          for j in range(len(mask_pred)):\n",
        "            tmp = mask_pred[j].detach().cpu()\n",
        "            tmp2 = (tmp[0]).numpy()\n",
        "            temp_mask = np.zeros((224, 224))\n",
        "            if(mode == 'Threshold'):\n",
        "              temp_locs = np.where(tmp2 > threshold)\n",
        "              temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            else:\n",
        "              mask_prob_uint8 = (tmp2 * 255).astype(np.uint8)\n",
        "              _, mask_otsu = cv2.threshold(mask_prob_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "              mask_otsu = mask_otsu.astype(np.uint8) / 255\n",
        "              temp_locs = np.where(mask_otsu == 1)\n",
        "              temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "            mask_pred_arrs.append(temp_mask)\n",
        "\n",
        "        if(len(mask_actual) == 0):\n",
        "          temp_mask_actual = np.zeros((224,224))\n",
        "          mask_actual_arrs.append(temp_mask_actual)\n",
        "        else:\n",
        "          for j in range(len(mask_actual)):\n",
        "            temp_actual = mask_actual[j].numpy()\n",
        "            temp_locs_actual = np.where(temp_actual == 1)\n",
        "            temp_mask_actual = np.zeros((224,224))\n",
        "            temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "            mask_actual_arrs.append(temp_mask_actual)\n",
        "\n",
        "        #print('HERE')\n",
        "        combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "        #print(combined_mask_pred)\n",
        "        #print(combined_mask_pred.shape)\n",
        "        #print('HERE2')\n",
        "        combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "        #print(combined_mask_actual)\n",
        "        #print(combined_mask_actual.shape)\n",
        "        #return\n",
        "        \n",
        "        TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "        TP_epoch += TP\n",
        "        FP_epoch += FP\n",
        "        TN_epoch += TN\n",
        "        FN_epoch += FN\n",
        "    \n",
        "    acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "    prec = precision(TP_epoch, FP_epoch)\n",
        "    rec = recall(TP_epoch, FN_epoch)\n",
        "    f1 = f1_score(prec, rec)\n",
        "    dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "    intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "    # print(acc)\n",
        "    # print(prec)\n",
        "    # print(rec)\n",
        "    # print(f1)\n",
        "    # print(dice)\n",
        "\n",
        "  return acc, prec, rec, f1, dice, intersection_over_union"
      ],
      "metadata": {
        "id": "JKUgqG3Sby-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JGkEk9LAiibb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "z1ra-dgwiibc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 14\n",
        "device = torch.device(device)\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "cgTVNaHBKRU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modes = [0.5,0.6,0.7,0.8,'Otsu']"
      ],
      "metadata": {
        "id": "fAG-qP1fKuN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_epochs = 50\n",
        "# iterations = np.arange(1,num_epochs + 1, 2)\n",
        "# for i in iterations:\n",
        "#   print(i)"
      ],
      "metadata": {
        "id": "LBJXHU4gcV5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "l2_reg = 5 * 1e-5\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9,  weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 50\n",
        "#num_epochs = 2\n",
        "iterations = np.arange(1,num_epochs + 1, 2)\n",
        "\n",
        "for epoch in iterations:\n",
        "    #temp_epoch = epoch + 1\n",
        "    temp_epoch = epoch\n",
        "    \n",
        "    PATH = '/content/drive/MyDrive/ee641/Project_Datasets/Model_Checkpoints_3/model_epoch_' + str(temp_epoch) + '.pth'\n",
        "    \n",
        "    #acc, prec, rec, f1, dice, intersection_over_union = evaluate(model, val_loader, device, temp_epoch)\n",
        "    #break\n",
        "    checkpoint = torch.load(PATH, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "    for mode in modes:\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        counter_eval = 0\n",
        "        TP_epoch = 0\n",
        "        FP_epoch = 0\n",
        "        TN_epoch = 0\n",
        "        FN_epoch = 0\n",
        "        for images, targets in train_loader:\n",
        "          image_batch = images.to(device)\n",
        "          targets_off_device = targets\n",
        "          target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "\n",
        "          outputs = model(image_batch)\n",
        "\n",
        "          for i in range(len(targets_off_device)):\n",
        "            mask_pred = list((outputs[i])['masks'])\n",
        "            mask_actual = list((targets_off_device[i])['masks'])\n",
        "            mask_pred_arrs = []\n",
        "            mask_actual_arrs = []\n",
        "\n",
        "            if(len(mask_pred) == 0):\n",
        "              temp_mask_pred = np.zeros((224,224))\n",
        "              mask_pred_arrs.append(temp_mask_pred)\n",
        "            else:\n",
        "              for j in range(len(mask_pred)):\n",
        "                tmp = mask_pred[j].detach().cpu()\n",
        "                tmp2 = (tmp[0]).numpy()\n",
        "                temp_mask = np.zeros((224, 224))\n",
        "                if(mode != 'Otsu'):\n",
        "                  temp_locs = np.where(tmp2 > mode)\n",
        "                  temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "                else:\n",
        "                  mask_prob_uint8 = (tmp2 * 255).astype(np.uint8)\n",
        "                  _, mask_otsu = cv2.threshold(mask_prob_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "                  mask_otsu = mask_otsu.astype(np.uint8) / 255\n",
        "                  temp_locs = np.where(mask_otsu == 1)\n",
        "                  temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "                mask_pred_arrs.append(temp_mask)\n",
        "\n",
        "            if(len(mask_actual) == 0):\n",
        "              temp_mask_actual = np.zeros((224,224))\n",
        "              mask_actual_arrs.append(temp_mask_actual)  \n",
        "            else:\n",
        "              for j in range(len(mask_actual)):\n",
        "                temp_actual = mask_actual[j].numpy()\n",
        "                temp_locs_actual = np.where(temp_actual == 1)\n",
        "                temp_mask_actual = np.zeros((224,224))\n",
        "                temp_mask_actual[temp_locs_actual[0], temp_locs_actual[1]] = 1\n",
        "                mask_actual_arrs.append(temp_mask_actual)\n",
        "            \n",
        "            combined_mask_pred = combine_masks(mask_pred_arrs)\n",
        "            combined_mask_actual = combine_masks(mask_actual_arrs)\n",
        "\n",
        "\n",
        "            TP, FP, TN, FN = confusion_matrix_elements(combined_mask_pred, combined_mask_actual)\n",
        "\n",
        "            TP_epoch += TP\n",
        "            FP_epoch += FP\n",
        "            TN_epoch += TN\n",
        "            FN_epoch += FN\n",
        "          counter_eval += 1\n",
        "          if(counter_eval*batch_size >= 750):\n",
        "            break\n",
        "      acc = accuracy(TP_epoch, FP_epoch, TN_epoch, FN_epoch)\n",
        "      prec = precision(TP_epoch, FP_epoch)\n",
        "      rec = recall(TP_epoch, FN_epoch)\n",
        "      f1 = f1_score(prec, rec)\n",
        "      dice = dice_coefficient(TP_epoch, FP_epoch, FN_epoch)\n",
        "      intersection_over_union = iou(TP_epoch, FP_epoch, FN_epoch)\n",
        "\n",
        "      # VALIDATE\n",
        "      model.eval()\n",
        "      if(mode != 'Otsu'):\n",
        "        acc_val, prec_val, rec_val, f1_val, dice_val, intersection_over_union_val = evaluate_masking(model, val_loader, device, temp_epoch, 'Threshold', mode)\n",
        "      else:\n",
        "        acc_val, prec_val, rec_val, f1_val, dice_val, intersection_over_union_val = evaluate_masking(model, val_loader, device, temp_epoch, 'Otsu', None)\n",
        "      print(str(mode), 'Thresholding Training Mask Accuracy in Epoch ', temp_epoch, ': ', acc)\n",
        "      print(str(mode), 'Thresholding Training Mask Precision in Epoch ', temp_epoch, ': ', prec)\n",
        "      print(str(mode), 'Thresholding Training Mask Recall in Epoch ', temp_epoch, ': ', rec)\n",
        "      print(str(mode), 'Thresholding Training Mask F1-Score in Epoch ', temp_epoch, ': ', f1)\n",
        "      print(str(mode), 'Thresholding Training DICE Score in Epoch ', temp_epoch, ': ', dice)\n",
        "      print(str(mode), 'Thresholding Training Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union)\n",
        "      print('\\n')\n",
        "      print(str(mode), 'Thresholding Validation Mask Accuracy in Epoch ', temp_epoch, ': ', acc_val)\n",
        "      print(str(mode), 'Thresholding Validation Mask Precision in Epoch ', temp_epoch, ': ', prec_val)\n",
        "      print(str(mode), 'Thresholding Validation Mask Recall in Epoch ', temp_epoch, ': ', rec_val)\n",
        "      print(str(mode), 'Thresholding Validation Mask F1-Score in Epoch ', temp_epoch, ': ', f1_val)\n",
        "      print(str(mode), 'Thresholding Validation DICE Score in Epoch ', temp_epoch, ': ', dice_val)\n",
        "      print(str(mode), 'Thresholding Validation Intersection Over Union(IoU) Score in Epoch ', temp_epoch, ': ', intersection_over_union_val)\n",
        "      print('\\n')\n",
        "\n",
        "      if(mode == 0.5):\n",
        "        acc_tr_epochs_05.append(acc)\n",
        "        pre_tr_epochs_05.append(prec)\n",
        "        rec_tr_epochs_05.append(rec)\n",
        "        f1_tr_epochs_05.append(f1)\n",
        "        dice_tr_epochs_05.append(dice)\n",
        "        iou_tr_epochs_05.append(intersection_over_union)\n",
        "\n",
        "        acc_val_epochs_05.append(acc_val)\n",
        "        pre_val_epochs_05.append(prec_val)\n",
        "        rec_val_epochs_05.append(rec_val)\n",
        "        f1_val_epochs_05.append(f1_val)\n",
        "        dice_val_epochs_05.append(dice_val)\n",
        "        iou_val_epochs_05.append(intersection_over_union_val)\n",
        "\n",
        "      elif(mode == 0.6):\n",
        "        acc_tr_epochs_06.append(acc)\n",
        "        pre_tr_epochs_06.append(prec)\n",
        "        rec_tr_epochs_06.append(rec)\n",
        "        f1_tr_epochs_06.append(f1)\n",
        "        dice_tr_epochs_06.append(dice)\n",
        "        iou_tr_epochs_06.append(intersection_over_union)\n",
        "\n",
        "        acc_val_epochs_06.append(acc_val)\n",
        "        pre_val_epochs_06.append(prec_val)\n",
        "        rec_val_epochs_06.append(rec_val)\n",
        "        f1_val_epochs_06.append(f1_val)\n",
        "        dice_val_epochs_06.append(dice_val)\n",
        "        iou_val_epochs_06.append(intersection_over_union_val)\n",
        "\n",
        "      elif(mode == 0.7):\n",
        "        acc_tr_epochs_07.append(acc)\n",
        "        pre_tr_epochs_07.append(prec)\n",
        "        rec_tr_epochs_07.append(rec)\n",
        "        f1_tr_epochs_07.append(f1)\n",
        "        dice_tr_epochs_07.append(dice)\n",
        "        iou_tr_epochs_07.append(intersection_over_union)\n",
        "\n",
        "        acc_val_epochs_07.append(acc_val)\n",
        "        pre_val_epochs_07.append(prec_val)\n",
        "        rec_val_epochs_07.append(rec_val)\n",
        "        f1_val_epochs_07.append(f1_val)\n",
        "        dice_val_epochs_07.append(dice_val)\n",
        "        iou_val_epochs_07.append(intersection_over_union_val)\n",
        "\n",
        "      elif(mode == 0.8):\n",
        "        acc_tr_epochs_08.append(acc)\n",
        "        pre_tr_epochs_08.append(prec)\n",
        "        rec_tr_epochs_08.append(rec)\n",
        "        f1_tr_epochs_08.append(f1)\n",
        "        dice_tr_epochs_08.append(dice)\n",
        "        iou_tr_epochs_08.append(intersection_over_union)\n",
        "\n",
        "        acc_val_epochs_08.append(acc_val)\n",
        "        pre_val_epochs_08.append(prec_val)\n",
        "        rec_val_epochs_08.append(rec_val)\n",
        "        f1_val_epochs_08.append(f1_val)\n",
        "        dice_val_epochs_08.append(dice_val)\n",
        "        iou_val_epochs_08.append(intersection_over_union_val)\n",
        "\n",
        "      else:\n",
        "        acc_tr_epochs_otsu.append(acc)\n",
        "        pre_tr_epochs_otsu.append(prec)\n",
        "        rec_tr_epochs_otsu.append(rec)\n",
        "        f1_tr_epochs_otsu.append(f1)\n",
        "        dice_tr_epochs_otsu.append(dice)\n",
        "        iou_tr_epochs_otsu.append(intersection_over_union)\n",
        "\n",
        "        acc_val_epochs_otsu.append(acc_val)\n",
        "        pre_val_epochs_otsu.append(prec_val)\n",
        "        rec_val_epochs_otsu.append(rec_val)\n",
        "        f1_val_epochs_otsu.append(f1_val)\n",
        "        dice_val_epochs_otsu.append(dice_val)\n",
        "        iou_val_epochs_otsu.append(intersection_over_union_val)\n",
        "\n",
        "scores_dict_05 = {}\n",
        "\n",
        "scores_dict_05['acc_tr'] = acc_tr_epochs_05\n",
        "scores_dict_05['pre_tr'] = pre_tr_epochs_05\n",
        "scores_dict_05['rec_tr'] = rec_tr_epochs_05\n",
        "scores_dict_05['f1_tr'] = f1_tr_epochs_05\n",
        "scores_dict_05['dice_tr'] = dice_tr_epochs_05\n",
        "scores_dict_05['iou_tr'] = iou_tr_epochs_05\n",
        "\n",
        "scores_dict_05['acc_val'] = acc_val_epochs_05\n",
        "scores_dict_05['pre_val'] = pre_val_epochs_05\n",
        "scores_dict_05['rec_val'] = rec_val_epochs_05\n",
        "scores_dict_05['f1_val'] = f1_val_epochs_05\n",
        "scores_dict_05['dice_val'] = dice_val_epochs_05\n",
        "scores_dict_05['iou_val'] = iou_val_epochs_05\n",
        "\n",
        "scores_dict_06 = {}\n",
        "\n",
        "scores_dict_06['acc_tr'] = acc_tr_epochs_06\n",
        "scores_dict_06['pre_tr'] = pre_tr_epochs_06\n",
        "scores_dict_06['rec_tr'] = rec_tr_epochs_06\n",
        "scores_dict_06['f1_tr'] = f1_tr_epochs_06\n",
        "scores_dict_06['dice_tr'] = dice_tr_epochs_06\n",
        "scores_dict_06['iou_tr'] = iou_tr_epochs_06\n",
        "\n",
        "scores_dict_06['acc_val'] = acc_val_epochs_06\n",
        "scores_dict_06['pre_val'] = pre_val_epochs_06\n",
        "scores_dict_06['rec_val'] = rec_val_epochs_06\n",
        "scores_dict_06['f1_val'] = f1_val_epochs_06\n",
        "scores_dict_06['dice_val'] = dice_val_epochs_06\n",
        "scores_dict_06['iou_val'] = iou_val_epochs_06\n",
        "\n",
        "scores_dict_07 = {}\n",
        "\n",
        "scores_dict_07['acc_tr'] = acc_tr_epochs_07\n",
        "scores_dict_07['pre_tr'] = pre_tr_epochs_07\n",
        "scores_dict_07['rec_tr'] = rec_tr_epochs_07\n",
        "scores_dict_07['f1_tr'] = f1_tr_epochs_07\n",
        "scores_dict_07['dice_tr'] = dice_tr_epochs_07\n",
        "scores_dict_07['iou_tr'] = iou_tr_epochs_07\n",
        "\n",
        "scores_dict_07['acc_val'] = acc_val_epochs_07\n",
        "scores_dict_07['pre_val'] = pre_val_epochs_07\n",
        "scores_dict_07['rec_val'] = rec_val_epochs_07\n",
        "scores_dict_07['f1_val'] = f1_val_epochs_07\n",
        "scores_dict_07['dice_val'] = dice_val_epochs_07\n",
        "scores_dict_07['iou_val'] = iou_val_epochs_07\n",
        "\n",
        "scores_dict_08 = {}\n",
        "\n",
        "scores_dict_08['acc_tr'] = acc_tr_epochs_08\n",
        "scores_dict_08['pre_tr'] = pre_tr_epochs_08\n",
        "scores_dict_08['rec_tr'] = rec_tr_epochs_08\n",
        "scores_dict_08['f1_tr'] = f1_tr_epochs_08\n",
        "scores_dict_08['dice_tr'] = dice_tr_epochs_08\n",
        "scores_dict_08['iou_tr'] = iou_tr_epochs_08\n",
        "\n",
        "scores_dict_08['acc_val'] = acc_val_epochs_08\n",
        "scores_dict_08['pre_val'] = pre_val_epochs_08\n",
        "scores_dict_08['rec_val'] = rec_val_epochs_08\n",
        "scores_dict_08['f1_val'] = f1_val_epochs_08\n",
        "scores_dict_08['dice_val'] = dice_val_epochs_08\n",
        "scores_dict_08['iou_val'] = iou_val_epochs_08\n",
        "\n",
        "scores_dict_otsu = {}\n",
        "\n",
        "scores_dict_otsu['acc_tr'] = acc_tr_epochs_otsu\n",
        "scores_dict_otsu['pre_tr'] = pre_tr_epochs_otsu\n",
        "scores_dict_otsu['rec_tr'] = rec_tr_epochs_otsu\n",
        "scores_dict_otsu['f1_tr'] = f1_tr_epochs_otsu\n",
        "scores_dict_otsu['dice_tr'] = dice_tr_epochs_otsu\n",
        "scores_dict_otsu['iou_tr'] = iou_tr_epochs_otsu\n",
        "\n",
        "scores_dict_otsu['acc_val'] = acc_val_epochs_otsu\n",
        "scores_dict_otsu['pre_val'] = pre_val_epochs_otsu\n",
        "scores_dict_otsu['rec_val'] = rec_val_epochs_otsu\n",
        "scores_dict_otsu['f1_val'] = f1_val_epochs_otsu\n",
        "scores_dict_otsu['dice_val'] = dice_val_epochs_otsu\n",
        "scores_dict_otsu['iou_val'] = iou_val_epochs_otsu"
      ],
      "metadata": {
        "id": "Cnr6lJ5nh2VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking 1: 0.5 Thresholding Performance"
      ],
      "metadata": {
        "id": "wtnlaGKwN3y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter_3(scores_dict_05)"
      ],
      "metadata": {
        "id": "yGvbB6mROQY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking 2: 0.6 Thresholding Performance"
      ],
      "metadata": {
        "id": "nM0vycSOOEPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter_3(scores_dict_06)"
      ],
      "metadata": {
        "id": "cvVIjXT8OWVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking 3: 0.7 Thresholding Performance"
      ],
      "metadata": {
        "id": "1pbCaV6oOECO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter_3(scores_dict_07)"
      ],
      "metadata": {
        "id": "DcZiW901OY6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking 4: 0.8 Thresholding Performance"
      ],
      "metadata": {
        "id": "KA04grguODx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter_3(scores_dict_08)"
      ],
      "metadata": {
        "id": "KIkFmjS1OcBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking 5: Otsu Thresholding Performance"
      ],
      "metadata": {
        "id": "H3ewFmJcODmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter_3(scores_dict_otsu)"
      ],
      "metadata": {
        "id": "Vzb3To2NLCES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparemeter Tuning Results: Best Setting: Masking 2: 0.6 Thresholding at Epoch 33, SGD+Momentum(0.9) with L2 Regularization Coefficient = 5 * 1e-5, Learning Rate = 1e-2, Learning Rate Scheduler: Every 10 steps by a factor of 0.1."
      ],
      "metadata": {
        "id": "K9asvfUCIUrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesizing a New Dataset Utilizing the Best Model:"
      ],
      "metadata": {
        "id": "2Ht3azxLJaGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "XNG6Q9BTQCPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/ee641/Project_Datasets/Indiana_University_Images_Zipped/images_normalized.zip"
      ],
      "metadata": {
        "id": "Q2FzOLBcPpEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_annotations = pd.read_csv('/content/drive/MyDrive/ee641/Project_Datasets/Indiana_University_Images_Zipped/indiana_images_info.csv')\n",
        "display(data_annotations)"
      ],
      "metadata": {
        "id": "5u_MfEmfQSBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_annotations.info()"
      ],
      "metadata": {
        "id": "7r0vc4TYRQkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_annotations.dropna(subset=['findings'], inplace=True)\n",
        "data_annotations.info()"
      ],
      "metadata": {
        "id": "LtjCk2sPSx3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_list = list(data_annotations['filename'])\n",
        "print(filename_list)"
      ],
      "metadata": {
        "id": "1HHcl--SS6b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/images_normalized/' + filename_list[3]\n",
        "temp_img = Image.open(path)\n",
        "print(type(temp_img))\n",
        "print(temp_img.size)\n",
        "#temp_img.show()\n",
        "print((temp_img.size)[0])\n",
        "print((temp_img.size)[1])\n",
        "temp_img = temp_img.convert('RGB')\n",
        "#print(temp_transform(temp_img).shape)\n",
        "temp_img = temp_img.resize((224, 224))\n",
        "print(temp_img.size)\n",
        "# temp_img.show()\n",
        "# print((temp_img.size)[0])\n",
        "# print((temp_img.size)[1])"
      ],
      "metadata": {
        "id": "x3MoRwk0VfFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoneTransform(object):\n",
        "    ''' Does nothing to the image. To be used instead of None '''\n",
        "    \n",
        "    def __call__(self, image):       \n",
        "        return image\n",
        "\n",
        "temp_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),            \n",
        "            transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform()            \n",
        "            ]) "
      ],
      "metadata": {
        "id": "C6yCKGiKZKMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_matrix = np.zeros((224,224,3))\n",
        "for i in range(len(filename_list)):\n",
        "  img_name = filename_list[i]\n",
        "  if(i % 100 == 0):\n",
        "    print(i)\n",
        "  #/content/images_normalized\n",
        "  path = '/content/images_normalized/' + img_name\n",
        "  temp_img = Image.open(path)\n",
        "  temp_img = temp_img.convert('RGB')\n",
        "  temp_img = temp_img.resize((224, 224))\n",
        "  temp_img_tensor = temp_transform(temp_img)\n",
        "  temp_img_tensor = temp_img_tensor.permute(1, 2, 0)\n",
        "  temp_img_numpy = temp_img_tensor.numpy()\n",
        "  sum_matrix = sum_matrix + temp_img_numpy"
      ],
      "metadata": {
        "id": "LkUh6zEsT7o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_matrix_1d = sum_matrix[:,:,0]\n",
        "sum_matrix_1d_avg = sum_matrix_1d / len(filename_list)\n",
        "mean_chest = np.mean(sum_matrix_1d_avg, axis = None)\n",
        "std_chest = np.std(sum_matrix_1d_avg, axis = None)\n",
        "print(\"Mean of the Gray Scale Training Chest Images of Pixels = \", mean_chest)\n",
        "print(\"Std of the Gray Scale Training Chest Images of Pixels = \", std_chest)"
      ],
      "metadata": {
        "id": "e_m_xOb8VSEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_root_dir = '/content/images_normalized'"
      ],
      "metadata": {
        "id": "AUMal6snbA1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Indiana_University_Dataset(Dataset):\n",
        "  def __init__(self, images_root_dir, filename_list, transform=None, cuda = True):\n",
        "    self.images_root_dir = images_root_dir\n",
        "    self.filename_list = filename_list\n",
        "    self.transform = transform\n",
        "    self.img_h = 224\n",
        "    self.img_w = 224\n",
        "    self.cuda = cuda\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filename_list)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image_filename = self.filename_list[idx]\n",
        "    image_directory = self.images_root_dir + '/' + image_filename\n",
        "\n",
        "    image = Image.open(image_directory)\n",
        "    org_image_width = (image.size)[0]\n",
        "    org_image_height = (image.size)[1]\n",
        "\n",
        "    # if(image.mode != 'RGB'):\n",
        "    #   image = image.convert('RGB')\n",
        "    \n",
        "    image = image.resize((self.img_h, self.img_w))\n",
        "\n",
        "    if(self.transform != None):\n",
        "      image = self.transform(image)\n",
        "\n",
        "    # target_dict = {}\n",
        "\n",
        "    # target_dict['image_name'] = image_filename\n",
        "\n",
        "    # target = target_dict\n",
        "\n",
        "    target = image_filename\n",
        "\n",
        "    return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    targets = []\n",
        "    for item in batch:\n",
        "        images.append(item[0])\n",
        "        targets.append(item[1])\n",
        "    images = torch.stack(images, 0)\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "SuKhwU_JaKWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "root_directory = '/content/images_normalized'\n",
        "\n",
        "\n",
        "class NoneTransform(object):\n",
        "  def __call__(self, image):\n",
        "    return image\n",
        "\n",
        "class GrayscaleToRGB:\n",
        "  def __call__(self, image):\n",
        "    if image.mode != 'RGB':\n",
        "      return image.convert('RGB')\n",
        "    return image\n",
        "\n",
        "mean_chest = 0.6262051540969282\n",
        "std_chest = 0.16896052000616008\n",
        "\n",
        "my_transform_with_Normalization = transforms.Compose([\n",
        "    GrayscaleToRGB(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    #transforms.Normalize([mean_chest, mean_chest, mean_chest], [std_chest, std_chest, std_chest])\n",
        "])\n",
        "\n",
        "\n",
        "#Mean of the Gray Scale Training Chest Images of Pixels =  0.5240804197105211\n",
        "#Std of the Gray Scale Training Chest Images of Pixels =  0.17148634738092733\n",
        "\n",
        "\n",
        "\n",
        "# my_transform_Specialized = transforms.Compose([\n",
        "#             transforms.ToTensor(),            \n",
        "#             transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform(),\n",
        "#             transforms.Normalize([mean_chest, mean_chest, mean_chest], [std_chest, std_chest, std_chest])                \n",
        "#             ]) \n",
        "\n",
        "# my_transform_ImageNet = transforms.Compose([\n",
        "#             transforms.ToTensor(),            \n",
        "#             transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if temp_img.mode!='RGB'  else NoneTransform(),\n",
        "#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                \n",
        "#             ]) \n",
        "\n",
        "dataset = Indiana_University_Dataset(root_directory, filename_list, transform=my_transform_with_Normalization, cuda = True)"
      ],
      "metadata": {
        "id": "lwxAxbPZchMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, shuffle = False, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "_bCjkaIkchMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_loader.dataset)"
      ],
      "metadata": {
        "id": "AoN0f1msgERQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "6iwXrqYTeIp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 14\n",
        "device = torch.device(device)\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "7WJkw1QAeIp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YrJGRZ9yQcIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masked & Non-Masked Image Creation"
      ],
      "metadata": {
        "id": "dQ3TuzVRk2Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/ee641/Project_Datasets/Model_Checkpoints_3/model_epoch_33.pth'\n",
        "checkpoint = torch.load(PATH, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "counter = 0\n",
        "mean_chest = [0.485, 0.456, 0.406]\n",
        "std_chest = [0.229, 0.224, 0.225]\n",
        "mean_for_unmasking = 0.6262051540969282\n",
        "rgb_mean_unmask = mean_for_unmasking * 255\n",
        "image_masked_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Masked_Synthesized_Indiana_University_Dataset/'\n",
        "image_non_masked_dir = '/content/drive/MyDrive/ee641/Project_Datasets/Non_Masked_Synthesized_Indiana_University_Dataset/'\n",
        "with torch.no_grad(): \n",
        "  for images, targets in data_loader:\n",
        "    model.eval()\n",
        "    image_batch = images.to(device)\n",
        "    predictions = model(image_batch)\n",
        "    #indices_of_images = np.arange(0,len(images),1)\n",
        "    #indices_of_images = np.arange(counter * len(images), (counter + 1) * len(images), 1)\n",
        "    for img_trg_index in range(len(images)):\n",
        "      mask_pred = list(predictions[img_trg_index]['masks'])\n",
        "      #file_name = list(targets[img_trg_index])\n",
        "      file_name = targets[img_trg_index]\n",
        "      fig_masked, ax_masked = plt.subplots()\n",
        "      fig_non_masked, ax_non_masked = plt.subplots()\n",
        "      actual_image = images[img_trg_index]\n",
        "      image_numpy = (actual_image.detach().cpu()).numpy()\n",
        "      actual_denormalized_image = denormalize_image(image_numpy, mean_chest, std_chest)\n",
        "      ax_masked.imshow(actual_denormalized_image)\n",
        "      ax_non_masked.imshow(actual_denormalized_image)\n",
        "      mask_pred_arrs = []\n",
        "        \n",
        "      for i in mask_pred:\n",
        "        tmp = i.detach().cpu()\n",
        "        tmp2 = (tmp[0]).numpy()\n",
        "        temp_mask = np.zeros((224, 224))\n",
        "        temp_locs = np.where(tmp2 > 0.6)\n",
        "        temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "        mask_pred_arrs.append(temp_mask)\n",
        "  \n",
        "      combined_mask_predicted = combine_masks(mask_pred_arrs)\n",
        "      predicted_mask_color = np.array([1, 0, 0, 0.25]) #Red\n",
        "      predicted_unmask_color = np.array([mean_for_unmasking, mean_for_unmasking, mean_for_unmasking, 0.5]) #Mean Unmask\n",
        "      predicted_mask_rgb = np.zeros((224, 224, 4))\n",
        "      predicted_non_mask_rgb = np.zeros((224, 224, 4))\n",
        "      predicted_mask_rgb[combined_mask_predicted == 1] = predicted_mask_color\n",
        "      #if(np.sum(combined_mask_predicted == True) == 0)\n",
        "      predicted_non_mask_rgb[combined_mask_predicted == 0] = predicted_unmask_color\n",
        "\n",
        "      ax_masked.imshow(predicted_mask_rgb)\n",
        "      ax_non_masked.imshow(predicted_non_mask_rgb)\n",
        "      ax_masked.axis('off')\n",
        "      ax_non_masked.axis('off')\n",
        "\n",
        "      temp_masked_filename = 'Masked_' + file_name\n",
        "      temp_non_masked_filename = 'Non_Masked_' + file_name\n",
        "\n",
        "      masked_directory = image_masked_dir + temp_masked_filename\n",
        "      non_masked_directory = image_non_masked_dir + temp_non_masked_filename\n",
        "\n",
        "      fig_masked.savefig(masked_directory, bbox_inches='tight', pad_inches=0)\n",
        "      fig_non_masked.savefig(non_masked_directory, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "      plt.close(fig_masked)\n",
        "      plt.close(fig_non_masked)\n",
        "    #counter += 1"
      ],
      "metadata": {
        "id": "a94hFnl_eIp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to script Final_Version_Instance_Segmentation_with_a_Novel_Mask_RCNN_14_Classes_Orkun_Bedir.ipynb"
      ],
      "metadata": {
        "id": "xUYt7Kgdhw3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Probable Model Trials"
      ],
      "metadata": {
        "id": "Dbvr2x0COiuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet Backbone"
      ],
      "metadata": {
        "id": "Ol1ClURYgQoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.ops import misc as misc_nn_ops\n",
        "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
        "from torchvision.models.densenet import densenet121\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "def get_densenet_backbone():\n",
        "    densenet = densenet121(pretrained=True)\n",
        "    backbone = torch.nn.Sequential(*list(densenet.children())[:-1])\n",
        "    backbone.out_channels = densenet.features[-1].num_features\n",
        "    return backbone\n",
        "\n",
        "def get_densenet_fpn():\n",
        "    backbone = get_densenet_backbone()\n",
        "    return_features = {'transition3': 'feat3', 'norm5': 'feat4'}\n",
        "    in_channels_list = [backbone.features[key].num_features for key in return_features]\n",
        "    out_channels = 256\n",
        "    fpn = FeaturePyramidNetwork(in_channels_list=in_channels_list, out_channels=out_channels, extra_blocks=None)\n",
        "    return backbone, fpn\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    backbone, fpn = get_densenet_fpn()\n",
        "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                       aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "    # Add MultiScaleRoIAlign for box and mask\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'],\n",
        "                                      output_size=7,\n",
        "                                      sampling_ratio=2)\n",
        "\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'],\n",
        "                                       output_size=14,\n",
        "                                       sampling_ratio=2)\n",
        "\n",
        "    model = MaskRCNN(backbone, num_classes, rpn_anchor_generator=anchor_generator, box_roi_pool=box_roi_pool, mask_roi_pool=mask_roi_pool, box_head=None, mask_head=None, keypoint_head=None, box_predictor=None, mask_predictor=None, keypoint_predictor=None, rpn_pre_nms_top_n_train=2000, rpn_pre_nms_top_n_test=1000, rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=1000, rpn_nms_thresh=0.7, rpn_fg_iou_thresh=0.7, rpn_bg_iou_thresh=0.3, rpn_batch_size_per_image=256, rpn_positive_fraction=0.5, box_score_thresh=0.05, box_nms_thresh=0.5, box_detections_per_img=100, box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5, box_batch_size_per_image=512, box_positive_fraction=0.25, bbox_reg_weights=None, mask_size=28, mask_positive_fraction=0.1, keypoint_size=None, keypoint_positive_fraction=None, keypoint_visibility_score_weight=0.5, keypoint_distribution_weight=0.25)\n",
        "\n",
        "    model.backbone.body = backbone\n",
        "    model.backbone.fpn = fpn\n",
        "\n",
        "    # Modify the box and mask predictor to match the new number of classes\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # Modify the mask predictor for the new backbone\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "MFhbpxvHjfgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End for Now"
      ],
      "metadata": {
        "id": "mtEBk28CWSFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle, Polygon\n",
        "def evaluate(model, val_loader, device, epoch):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "      model.eval()\n",
        "      image_batch = images.to(device)\n",
        "      #target_batch = [{'boxes':dictionary['boxes'].to(device), 'labels':dictionary['labels'].to(device), 'masks':dictionary['masks'].to(device)} for dictionary in targets]\n",
        "      predictions = model(image_batch)\n",
        "\n",
        "      box_pred_1 = list(predictions[0]['boxes'])\n",
        "      box_pred_2 = list(predictions[5]['boxes'])\n",
        "      box_pred_3 = list(predictions[10]['boxes'])\n",
        "      box_pred_4 = list(predictions[15]['boxes'])\n",
        "\n",
        "      box_actual_1 = list(targets[0]['boxes'])\n",
        "      box_actual_2 = list(targets[5]['boxes'])\n",
        "      box_actual_3 = list(targets[10]['boxes'])\n",
        "      box_actual_4 = list(targets[15]['boxes'])\n",
        "\n",
        "      mask_pred_1 = list(predictions[0]['masks'])\n",
        "      mask_pred_2 = list(predictions[5]['masks'])\n",
        "      mask_pred_3 = list(predictions[10]['masks'])\n",
        "      mask_pred_4 = list(predictions[15]['masks'])\n",
        "\n",
        "      mask_actual_1 = list(targets[0]['masks'])\n",
        "      mask_actual_2 = list(targets[5]['masks'])\n",
        "      mask_actual_3 = list(targets[10]['masks'])\n",
        "      mask_actual_4 = list(targets[15]['masks'])\n",
        "\n",
        "      actual_image_1 = images[0]\n",
        "      actual_image_2 = images[5]\n",
        "      actual_image_3 = images[10]\n",
        "      actual_image_4 = images[15]\n",
        "\n",
        "      fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
        "\n",
        "      ax[0, 0].imshow(actual_image_1.permute(1, 2, 0))\n",
        "      for i in mask_pred_1:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          predicted_mask_color = np.array([0, 1, 0]) #Green\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 3))\n",
        "          predicted_mask_rgb[temp_mask == 1] = predicted_mask_color\n",
        "          ax[0, 0].imshow(predicted_mask_rgb, alpha = 0.5)\n",
        "      for i in mask_actual_1:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          actual_mask_color = np.array([1, 0, 0]) #Red\n",
        "          actual_mask_rgb = np.zeros((224, 224, 3))\n",
        "          actual_mask_rgb[temp_mask == 1] = actual_mask_color\n",
        "          ax[0, 0].imshow(actual_mask_rgb, alpha = 0.5)\n",
        "      for i in box_pred_1:\n",
        "        tmp = i.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1.2, edgecolor='g', facecolor='none')\n",
        "        ax[0, 0].add_patch(tmp_rect)\n",
        "      for j in box_actual_1:\n",
        "        tmp = j.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax[0, 0].add_patch(tmp_rect)\n",
        "\n",
        "\n",
        "      ax[0, 1].imshow(actual_image_2.permute(1, 2, 0))\n",
        "      for i in mask_pred_2:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          predicted_mask_color = np.array([0, 1, 0]) #Green\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 3))\n",
        "          predicted_mask_rgb[temp_mask == 1] = predicted_mask_color\n",
        "          ax[0, 1].imshow(predicted_mask_rgb, alpha = 0.5)\n",
        "      for i in mask_actual_2:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          actual_mask_color = np.array([1, 0, 0]) #Red\n",
        "          actual_mask_rgb = np.zeros((224, 224, 3))\n",
        "          actual_mask_rgb[temp_mask == 1] = actual_mask_color\n",
        "          ax[0, 1].imshow(actual_mask_rgb, alpha = 0.5)\n",
        "      for i in box_pred_2:\n",
        "        tmp = i.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1.2, edgecolor='g', facecolor='none')\n",
        "        ax[0, 1].add_patch(tmp_rect)\n",
        "      for j in box_actual_2:\n",
        "        tmp = j.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax[0, 1].add_patch(tmp_rect)\n",
        "\n",
        "\n",
        "      ax[1, 0].imshow(actual_image_3.permute(1, 2, 0))\n",
        "      for i in mask_pred_3:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          predicted_mask_color = np.array([0, 1, 0]) #Green\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 3))\n",
        "          predicted_mask_rgb[temp_mask == 1] = predicted_mask_color\n",
        "          ax[1, 0].imshow(predicted_mask_rgb, alpha = 0.5)\n",
        "      for i in mask_actual_3:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          actual_mask_color = np.array([1, 0, 0]) #Red\n",
        "          actual_mask_rgb = np.zeros((224, 224, 3))\n",
        "          actual_mask_rgb[temp_mask == 1] = actual_mask_color\n",
        "          ax[1, 0].imshow(actual_mask_rgb, alpha = 0.5)\n",
        "      for i in box_pred_3:\n",
        "        tmp = i.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1.2, edgecolor='g', facecolor='none')\n",
        "        ax[1, 0].add_patch(tmp_rect)\n",
        "      for j in box_actual_3:\n",
        "        tmp = j.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax[1, 0].add_patch(tmp_rect)\n",
        "\n",
        "      ax[1, 1].imshow(actual_image_4.permute(1, 2, 0))\n",
        "      for i in mask_pred_4:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          predicted_mask_color = np.array([0, 1, 0]) #Green\n",
        "          predicted_mask_rgb = np.zeros((224, 224, 3))\n",
        "          predicted_mask_rgb[temp_mask == 1] = predicted_mask_color\n",
        "          ax[1, 1].imshow(predicted_mask_rgb, alpha = 0.5)\n",
        "      for i in mask_actual_4:\n",
        "        tmp = i.detach().cpu()\n",
        "        for j in range(len(tmp)):\n",
        "          tmp2 = (tmp[j]).numpy()\n",
        "          temp_locs = np.where(tmp2 > 0.5)\n",
        "          temp_mask = np.zeros((224, 224))\n",
        "          temp_mask[temp_locs[0], temp_locs[1]] = 1\n",
        "          actual_mask_color = np.array([1, 0, 0]) #Red\n",
        "          actual_mask_rgb = np.zeros((224, 224, 3))\n",
        "          actual_mask_rgb[temp_mask == 1] = actual_mask_color\n",
        "          ax[1, 1].imshow(actual_mask_rgb, alpha = 0.5)\n",
        "      for i in box_pred_4:\n",
        "        tmp = i.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=1.2, edgecolor='g', facecolor='none')\n",
        "        ax[1, 1].add_patch(tmp_rect)\n",
        "      for j in box_actual_4:\n",
        "        tmp = j.detach().cpu().numpy()\n",
        "        tmp_rect = Rectangle((tmp[0], tmp[3]), tmp[2] - tmp[0], tmp[3] - tmp[1], linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax[1, 1].add_patch(tmp_rect)\n",
        "\n",
        "      image_dir = '/content/Boxes_Images_Resized/'\n",
        "      temp_filename = image_dir + 'Epoch_' + str(epoch) + '_BBox_Preds_BLUE_Mask_Preds_GREEN_BBox_Actual_RED_Mask_Actual_RED.png'\n",
        "      temp_title = 'Epoch ' + str(epoch) + ' BBox Predictions (BLUE) vs. Actual BBox(RED) and Mask Predictions (GREEN) vs. Actual Masks(RED)'\n",
        "      #plt.title(temp_title)\n",
        "      fig.suptitle(temp_title)\n",
        "      plt.show()\n",
        "      fig.savefig(temp_filename)\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "iVDZ808P2ieo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, targets = next(iter(val_loader))"
      ],
      "metadata": {
        "id": "CpFueIe08Wz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = images[0]\n",
        "sample_target = targets[0]\n",
        "print(sample_image)\n",
        "print(sample_target)\n",
        "sample_boxes = sample_target['boxes']\n",
        "sample_masks = sample_target['masks']\n",
        "sample_labels = sample_target['labels']"
      ],
      "metadata": {
        "id": "2t7oDBKg8Wz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "model_org = get_model_instance_segmentation(num_classes)"
      ],
      "metadata": {
        "id": "uwmYAiTF9I7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_org.eval()\n",
        "image, target = next(iter(val_loader))\n",
        "#sample_outputs = model(sample_image)\n",
        "#image_list = [image.squeeze(0)]\n",
        "with torch.no_grad():\n",
        "  output_eval = model_org(image_list)\n",
        "\n",
        "# model_org.train()\n",
        "# output_train = model_org(image_list, target)\n"
      ],
      "metadata": {
        "id": "kT4enPEw8Wz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = list(output_eval[0]['masks'])\n",
        "for i in a:\n",
        "  temp = i.numpy()\n",
        "  print(temp[0])\n",
        "  print(temp[0].shape)\n",
        "  loc = np.where(temp[0] > 0.5)\n",
        "  print(loc)\n",
        "  print((temp[0])[162][140])\n",
        "  #print()\n",
        "  break\n",
        "mask = np.zeros((224, 224))\n",
        "mask[loc[0], loc[1]] = 1\n",
        "#print(loc[0])\n",
        "#print(loc[0][0])\n",
        "print(mask)\n",
        "print(np.where(mask == 1))"
      ],
      "metadata": {
        "id": "t5e67bSI9SH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_backbone = CustomKerasBackbone(pytorch_backbone)"
      ],
      "metadata": {
        "id": "wseUgqCtv53N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "model = get_model_instance_segmentation(custom_backbone, num_classes)"
      ],
      "metadata": {
        "id": "KVrxR2euv53O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_rcnn_model.transform.image_mean = [0.0, 0.0, 0.0]\n",
        "mask_rcnn_model.transform.image_std = [1.0, 1.0, 1.0]"
      ],
      "metadata": {
        "id": "ECF7obxK-nUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_rcnn_model.eval()\n",
        "image, target = next(iter(train_loader))\n",
        "#sample_outputs = model(sample_image)\n",
        "image_list = [image.squeeze(0)]\n",
        "with torch.no_grad():\n",
        "    output = mask_rcnn_model(image_list)\n",
        "#sample_outputs = mask_rcnn_model(sample_image)"
      ],
      "metadata": {
        "id": "gjlzDQ_QuKgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(image_list)"
      ],
      "metadata": {
        "id": "kf4H2tLx6cnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COCO_Dataset(Dataset):\n",
        "    def __init__(self, root_dir, annFile, transform=None, cuda=True, set_name = None, mapping=None):\n",
        "        self.mappping = mapping \n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.imgs = os.listdir(root_dir)\n",
        "        self.mode = set_name\n",
        "        # annotationsx\n",
        "        self.ct = COCO_Text(annFile)\n",
        "        if(self.mode == 'train'):\n",
        "          self.imgIds = self.ct.getImgIds(imgIds=self.ct.train, \n",
        "                      catIds=[('legibility','legible'),('class','machine printed')])\n",
        "          self.imgIds.remove(275939)\n",
        "          self.imgIds.remove(443671)\n",
        "        elif(self.mode == 'val'):\n",
        "          self.imgIds = self.ct.getImgIds(imgIds=self.ct.train, \n",
        "                      catIds=[('legibility','legible'),('class','machine printed')])\n",
        "          self.imgIds.remove(275939)\n",
        "          self.imgIds.remove(443671)\n",
        "        else:\n",
        "          self.imgIds = self.ct.getImgIds(imgIds=self.ct.test, \n",
        "                      catIds=[('legibility','legible'),('class','machine printed')])\n",
        "        \n",
        "        for imgId in self.imgIds:\n",
        "            file_name = self.ct.loadImgs(imgId)[0]['file_name']\n",
        "            if file_name not in self.imgs:\n",
        "                self.imgIds.remove(imgId)\n",
        "        # manual exclude\n",
        "        #self.imgIds.remove(275939)\n",
        "        #self.imgIds.remove(443671)\n",
        "\n",
        "        # remaining images\n",
        "        print(f\"remaining images in ann file: {len(self.imgIds)}, remaining images in folder: {len(self.imgs)}\")\n",
        "\n",
        "        self.imgIds.sort()\n",
        "        # sort the images in same order as the annotations\n",
        "        self.imgs = [self.ct.loadImgs(imgId)[0]['file_name'] for imgId in self.imgIds]\n",
        "\n",
        "        self.img_h = 224\n",
        "        self.img_w = 224\n",
        "        self.cuda = cuda\n",
        "\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # TODO: return image / bounding-box [list] pair for self.imgIds[idx]\n",
        "        # resize the image to conform to your model input and transformed\n",
        "        # bounding box coordinates\n",
        "        \n",
        "        # see COCO_Text helper (i.e., self.ct)\n",
        "        # return image, target\n",
        "        temp_img = self.ct.loadImgs(self.imgIds[idx])[0]\n",
        "\n",
        "        #temp_img = self.imgs[idx]\n",
        "\n",
        "        image_height = temp_img['height']\n",
        "        image_width = temp_img['width']\n",
        "        image_directory = self.root_dir + '/' + temp_img['file_name']\n",
        "        #image = io.imread('%s/train/%s'%(self.root_dir,temp_img['file_name']))\n",
        "        image = Image.open(image_directory)\n",
        "        #image = io.imread(image_directory)\n",
        "        annotation_IDs = self.ct.getAnnIds(imgIds=temp_img['id'])\n",
        "        annotations = self.ct.loadAnns(ids = annotation_IDs)\n",
        "        bounding_box_coordinates = []\n",
        "        #val_bbox_coordinates = []\n",
        "        labels = []\n",
        "        for annotation_item in annotations:\n",
        "\n",
        "          #if('utf8_string' in annotation_item.keys()):\n",
        "          #  temp_name_label = annotation_item['utf8_string']\n",
        "          #else:\n",
        "          #  temp_name_label = str((tmp_anns[j])['id'])\n",
        "\n",
        "          #labels.append(self.mapping[temp_name_label])\n",
        "          labels.append(1)\n",
        "\n",
        "          bounding_box_details = annotation_item['bbox']\n",
        "          left_bottom_x = bounding_box_details[0]\n",
        "          left_bottom_y = bounding_box_details[1]\n",
        "          left_top_x = left_bottom_x\n",
        "          left_top_y = left_bottom_y + bounding_box_details[3]\n",
        "          right_bottom_x = left_top_x + bounding_box_details[2]\n",
        "          right_bottom_y = left_bottom_y\n",
        "          right_top_x = right_bottom_x\n",
        "          right_top_y = left_top_y\n",
        "          #validation_bbox = [left_bottom_x, left_bottom_y, right_top_x, right_top_y]\n",
        "          #val_bbox_coordinates.append(validation_bbox)\n",
        "\n",
        "\n",
        "\n",
        "          scaled_left_top_y = (self.img_h * left_top_y) / image_height\n",
        "          scaled_left_top_x = (self.img_w * left_top_x) / image_width\n",
        "          scaled_left_bottom_y = (self.img_h * left_bottom_y) / image_height\n",
        "          scaled_left_bottom_x = (self.img_w * left_bottom_x) / image_width\n",
        "          scaled_right_top_y = (self.img_h * right_top_y) / image_height\n",
        "          scaled_right_top_x = (self.img_w * right_top_x) / image_width\n",
        "          scaled_right_bottom_y = (self.img_h * right_bottom_y) / image_height\n",
        "          scaled_right_bottom_x = (self.img_w * right_bottom_x) / image_width\n",
        "          temp_bounding_box = [scaled_left_top_y, scaled_left_top_x, \n",
        "                               scaled_left_bottom_y, scaled_left_bottom_x,\n",
        "                               scaled_right_top_y, scaled_right_top_x, \n",
        "                               scaled_right_bottom_y, scaled_right_bottom_x]\n",
        "          xmin, ymin, xmax, ymax = scaled_left_bottom_x, scaled_left_bottom_y, scaled_right_top_x, scaled_right_top_y\n",
        "          formatted_box = [xmin, ymin, xmax, ymax]\n",
        "          #bounding_box_coordinates.append(temp_bounding_box)\n",
        "          bounding_box_coordinates.append(formatted_box)\n",
        "      \n",
        "        #print(image.shape)\n",
        "\n",
        "        if(image.mode != 'RGB'):\n",
        "          image = image.convert('RGB')\n",
        "\n",
        "        \n",
        "        image_1 = image.resize((self.img_h, self.img_w))\n",
        "        transformed_image = self.transform(image_1)\n",
        "\n",
        "        #print(transformed_image.shape)\n",
        "\n",
        "        transformed_labels = torch.LongTensor(labels)\n",
        "        transformed_bbox = torch.FloatTensor(bounding_box_coordinates)\n",
        "        #transformed_labels = np.array(labels, dtype=np.int64)\n",
        "        #transformed_bbox = np.array(labels, dtype=np.float32)\n",
        "        #transformed_bbox = torch.as_tensor(bounding_box_coordinates, dtype=torch.float32)\n",
        "        #transformed_labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        #target = []\n",
        "\n",
        "        temp_dict = {}\n",
        "        temp_dict['boxes'] = transformed_bbox\n",
        "        temp_dict['labels'] = transformed_labels\n",
        "        target = temp_dict\n",
        "        #target.append(temp_dict)\n",
        "\n",
        "        #return transformed_image, bounding_box_coordinates\n",
        "        #if(self.mode == 'train'):\n",
        "        #  return transformed_image, target\n",
        "        #else:\n",
        "        #  return transformed_image, target, val_bbox_coordinates, image, image_height, image_width\n",
        "        \n",
        "        return transformed_image, target\n",
        "\n",
        "        #raise NotImplementedError(\"CocoDataset::__getitem__()\")\n",
        "\n",
        "\n",
        "# coalate_fn is used to collate the data into batches\n",
        "#def collate_fn(batch, mode = None):\n",
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    targets = []\n",
        "    #val_bbox_coordinates = []\n",
        "    #plain_images = []\n",
        "    #image_heights = []\n",
        "    #image_widths = []\n",
        "    for item in batch:\n",
        "        images.append(item[0])\n",
        "        targets.append(item[1])\n",
        "    images = torch.stack(images, 0)\n",
        "    #if(mode == 'train'):\n",
        "    return images, targets\n",
        "    #else:\n",
        "    #return images\n",
        "    #return images, targets"
      ],
      "metadata": {
        "id": "1dyxvV9110Cc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}